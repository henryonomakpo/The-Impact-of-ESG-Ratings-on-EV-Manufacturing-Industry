{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxFRc1VMA5Tw4rvmRZaPKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henryonomakpo/The-Impact-of-ESG-Ratings-on-EV-Manufacturing-Industry/blob/main/Panel_Regression_ESG_data_for_Transportation%2C_3PL_providers%2C_and_Courier_service_sector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Required libraries, yfinance, statsmodels, pandas, numpy, scikit-learn, xlsxwriter, linearmodels\n",
        "!pip install yesg\n",
        "!pip install yfinance\n",
        "!pip install statsmodels\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install xlsxwriter\n",
        "!pip install linearmodels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-X8hNeUto7p",
        "outputId": "bda5e443-4e5e-4a35-fcde-100c911f8a5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yesg\n",
            "  Downloading yesg-2.1.1.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: yesg\n",
            "  Building wheel for yesg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yesg: filename=yesg-2.1.1-py3-none-any.whl size=6105 sha256=fbb545ee599add2bf316cd4c135c1cae4d572ba2d57aa249b957fe6b8e34e006\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/8d/48/f5e8ff0315a46301e15c68371e297b460b33e1c846117725bc\n",
            "Successfully built yesg\n",
            "Installing collected packages: yesg\n",
            "Successfully installed yesg-2.1.1\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.56)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.0.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.15.2)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n",
            "Collecting linearmodels\n",
            "  Downloading linearmodels-6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from linearmodels) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from linearmodels) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from linearmodels) (1.15.2)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from linearmodels) (0.14.4)\n",
            "Collecting mypy-extensions>=0.4 (from linearmodels)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from linearmodels) (3.0.12)\n",
            "Collecting pyhdfe>=0.1 (from linearmodels)\n",
            "  Downloading pyhdfe-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting formulaic>=1.0.0 (from linearmodels)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting setuptools-scm<9.0.0,>=8.0.0 (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels)\n",
            "  Downloading setuptools_scm-8.3.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=1.0.0->linearmodels)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=1.0.0->linearmodels) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=1.0.0->linearmodels) (1.17.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->linearmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->linearmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->linearmodels) (2025.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (75.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.0->linearmodels) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->linearmodels) (1.17.0)\n",
            "Downloading linearmodels-6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pyhdfe-0.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading setuptools_scm-8.3.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: setuptools-scm, mypy-extensions, interface-meta, pyhdfe, formulaic, linearmodels\n",
            "Successfully installed formulaic-1.1.1 interface-meta-1.3.0 linearmodels-6.1 mypy-extensions-1.1.0 pyhdfe-0.2.0 setuptools-scm-8.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch ESG data for Transportation, 3PL providers, and Courier service sector"
      ],
      "metadata": {
        "id": "MejjxhSNtO-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKIZCEBstOEJ",
        "outputId": "b02dfee0-072a-403b-e803-80b1f61d56b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ESG Data Fetching Script for Global Transportation Firms ---\n",
            "\n",
            "Attempting to mount Google Drive at /content/drive...\n",
            "Failed to mount Google Drive: mount failed\n",
            "Output CSV will be saved locally as 'historic_esg_scores_global_transportation.csv'.\n",
            "\n",
            "Tickers to fetch ESG data for (15 total): ['UPS', 'FDX', 'DPSGY', 'AMKBY', 'KHNGY', 'DSDVY', 'UNP', 'CNI', 'CP', 'CSX', 'XPO', 'ODFL', 'JBHT', 'ZIM', 'JYD']\n",
            "Starting ESG data download loop...\n",
            "WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\n",
            "Note: ESG data is typically published annually, so expect one data point per year if available.\n",
            "  -> Processing: UPS (United Parcel Service)\n",
            "    -> Success: Found 128 historic ESG data points for UPS (United Parcel Service).\n",
            "  -> Processing: FDX (FedEx Corporation)\n",
            "    -> Success: Found 128 historic ESG data points for FDX (FedEx Corporation).\n",
            "  -> Processing: DPSGY (Deutsche Post DHL Group)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for DPSGY (Deutsche Post DHL Group).\n",
            "  -> Processing: AMKBY (A.P. Møller - Mærsk)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for AMKBY (A.P. Møller - Mærsk).\n",
            "  -> Processing: KHNGY (Kuehne + Nagel International)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for KHNGY (Kuehne + Nagel International).\n",
            "  -> Processing: DSDVY (DSV A/S)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for DSDVY (DSV A/S).\n",
            "  -> Processing: UNP (Union Pacific Corp.)\n",
            "    -> Success: Found 128 historic ESG data points for UNP (Union Pacific Corp.).\n",
            "  -> Processing: CNI (Canadian National Railway)\n",
            "    -> Success: Found 128 historic ESG data points for CNI (Canadian National Railway).\n",
            "  -> Processing: CP (Canadian Pacific Kansas City)\n",
            "    -> Success: Found 128 historic ESG data points for CP (Canadian Pacific Kansas City).\n",
            "  -> Processing: CSX (CSX Corporation)\n",
            "    -> Success: Found 128 historic ESG data points for CSX (CSX Corporation).\n",
            "  -> Processing: XPO (XPO, Inc.)\n",
            "    -> Success: Found 6 historic ESG data points for XPO (XPO, Inc.).\n",
            "  -> Processing: ODFL (Old Dominion Freight Line)\n",
            "    -> Success: Found 7 historic ESG data points for ODFL (Old Dominion Freight Line).\n",
            "  -> Processing: JBHT (J.B. Hunt Transport)\n",
            "    -> Success: Found 128 historic ESG data points for JBHT (J.B. Hunt Transport).\n",
            "  -> Processing: ZIM (ZIM Integrated Shipping)\n",
            "    -> Success: Found 6 historic ESG data points for ZIM (ZIM Integrated Shipping).\n",
            "  -> Processing: JYD (Jayud Global Logistics)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for JYD (Jayud Global Logistics).\n",
            "\n",
            "Combining collected historic ESG data...\n",
            "  -> Date column converted to datetime and data sorted.\n",
            "\n",
            "Preview of combined historic ESG data:\n",
            "        Date  Total-Score  E-Score  S-Score  G-Score Ticker\n",
            "0 2014-09-01         66.0     62.0     61.0     79.0    CNI\n",
            "1 2014-10-01         65.0     62.0     61.0     76.0    CNI\n",
            "2 2014-11-01         65.0     62.0     61.0     76.0    CNI\n",
            "3 2014-12-01         64.0     59.0     61.0     76.0    CNI\n",
            "4 2015-01-01         64.0     59.0     61.0     76.0    CNI\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 915 entries, 0 to 914\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   Date         915 non-null    datetime64[ns]\n",
            " 1   Total-Score  617 non-null    float64       \n",
            " 2   E-Score      617 non-null    float64       \n",
            " 3   S-Score      617 non-null    float64       \n",
            " 4   G-Score      617 non-null    float64       \n",
            " 5   Ticker       915 non-null    object        \n",
            "dtypes: datetime64[ns](1), float64(4), object(1)\n",
            "memory usage: 43.0+ KB\n",
            "\n",
            "Total rows collected: 915\n",
            "\n",
            "Saving historic ESG data to: historic_esg_scores_global_transportation.csv ...\n",
            "Historic ESG data saved successfully.\n",
            "\n",
            "--- Historic ESG Fetching Summary ---\n",
            "Successfully fetched historic ESG data for (10 tickers): ['UPS', 'FDX', 'UNP', 'CNI', 'CP', 'CSX', 'XPO', 'ODFL', 'JBHT', 'ZIM']\n",
            "Failed or no historic ESG data for (5 tickers): ['DPSGY', 'AMKBY', 'KHNGY', 'DSDVY', 'JYD']\n",
            "--- Script Finished ---\n"
          ]
        }
      ],
      "source": [
        "# Required libraries: yesg, pandas\n",
        "# Optional for Google Drive: google.colab\n",
        "# If running locally, you may need to install these:\n",
        "# !pip install yesg pandas\n",
        "\n",
        "import yesg\n",
        "import pandas as pd\n",
        "import time # To add delays between API calls\n",
        "import warnings # To potentially suppress warnings\n",
        "\n",
        "# Attempt to import and use Google Drive specific libraries only if needed\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    google_colab_available = True\n",
        "except ImportError:\n",
        "    google_colab_available = False\n",
        "    print(\"Google Colab environment not detected. Will save CSV locally.\")\n",
        "\n",
        "print(\"--- ESG Data Fetching Script for Global Transportation Firms ---\")\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# List of tickers for Global Transportation firms\n",
        "# Note: Data availability may vary significantly by ticker and source.\n",
        "TICKERS_GLOBAL_TRANSPORTATION = [\n",
        "    'UPS',    # United Parcel Service (NYSE)\n",
        "    'FDX',    # FedEx Corporation (NYSE)\n",
        "    'DPSGY',  # Deutsche Post DHL Group (OTC)\n",
        "    'AMKBY',  # A.P. Møller - Mærsk (OTC)\n",
        "    'KHNGY',  # Kuehne + Nagel International (OTC)\n",
        "    'DSDVY',  # DSV A/S (OTC)\n",
        "    'UNP',    # Union Pacific Corp. (NYSE)\n",
        "    'CNI',    # Canadian National Railway (NYSE)\n",
        "    'CP',     # Canadian Pacific Kansas City (NYSE)\n",
        "    'CSX',    # CSX Corporation (NASDAQ)\n",
        "    'XPO',    # XPO, Inc. (NYSE)\n",
        "    'ODFL',   # Old Dominion Freight Line (NASDAQ)\n",
        "    'JBHT',   # J.B. Hunt Transport (NASDAQ)\n",
        "    'ZIM',    # ZIM Integrated Shipping (NYSE)\n",
        "    'JYD',    # Jayud Global Logistics (NASDAQ) - Note: Low Market Cap, data might be sparse\n",
        "]\n",
        "\n",
        "# Optional mapping for clearer output\n",
        "TICKER_NAMES = {\n",
        "    'UPS': 'United Parcel Service', 'FDX': 'FedEx Corporation',\n",
        "    'DPSGY': 'Deutsche Post DHL Group', 'AMKBY': 'A.P. Møller - Mærsk',\n",
        "    'KHNGY': 'Kuehne + Nagel International', 'DSDVY': 'DSV A/S',\n",
        "    'UNP': 'Union Pacific Corp.', 'CNI': 'Canadian National Railway',\n",
        "    'CP': 'Canadian Pacific Kansas City', 'CSX': 'CSX Corporation',\n",
        "    'XPO': 'XPO, Inc.', 'ODFL': 'Old Dominion Freight Line',\n",
        "    'JBHT': 'J.B. Hunt Transport', 'ZIM': 'ZIM Integrated Shipping',\n",
        "    'JYD': 'Jayud Global Logistics'\n",
        "}\n",
        "\n",
        "# Define where to save the output file\n",
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "OUTPUT_FILENAME = 'historic_esg_scores_global_transportation.csv'\n",
        "OUTPUT_PATH_DRIVE = f'{DRIVE_MOUNT_PATH}/My Drive/{OUTPUT_FILENAME}' # Standard Google Drive path\n",
        "OUTPUT_PATH_LOCAL = OUTPUT_FILENAME # Save in current directory if Drive fails\n",
        "\n",
        "# Delay between API calls (in seconds) to avoid potential blocking\n",
        "API_DELAY = 0.8 # Slightly increased delay as a precaution\n",
        "\n",
        "# --- Mount Google Drive (if in Colab) ---\n",
        "drive_mounted = False\n",
        "save_path = OUTPUT_PATH_LOCAL # Default save path\n",
        "\n",
        "if google_colab_available:\n",
        "    try:\n",
        "        print(f\"\\nAttempting to mount Google Drive at {DRIVE_MOUNT_PATH}...\")\n",
        "        # Suppress specific warnings that might appear during mounting\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            drive.mount(DRIVE_MOUNT_PATH, force_remount=True) # force_remount=True can help with issues\n",
        "\n",
        "        drive_mounted = True\n",
        "        save_path = OUTPUT_PATH_DRIVE\n",
        "        print(\"Google Drive mounted successfully.\")\n",
        "        print(f\"Output CSV will be saved to Google Drive at '{save_path}'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to mount Google Drive: {e}\")\n",
        "        print(f\"Output CSV will be saved locally as '{OUTPUT_PATH_LOCAL}'.\")\n",
        "else:\n",
        "    # Not in Colab, saving locally\n",
        "    print(f\"\\nOutput CSV will be saved locally as '{OUTPUT_PATH_LOCAL}'.\")\n",
        "\n",
        "\n",
        "# --- Data Fetching Loop ---\n",
        "print(f\"\\nTickers to fetch ESG data for ({len(TICKERS_GLOBAL_TRANSPORTATION)} total): {TICKERS_GLOBAL_TRANSPORTATION}\")\n",
        "print(\"Starting ESG data download loop...\")\n",
        "print(\"WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\")\n",
        "print(\"Note: ESG data is typically published annually, so expect one data point per year if available.\")\n",
        "\n",
        "\n",
        "# Initialize lists to store results and track progress\n",
        "all_esg_data_list = []\n",
        "successful_tickers = []\n",
        "failed_tickers = []\n",
        "\n",
        "for ticker in TICKERS_GLOBAL_TRANSPORTATION:\n",
        "    ticker_name = TICKER_NAMES.get(ticker, ticker) # Use mapped name if available\n",
        "    print(f\"  -> Processing: {ticker} ({ticker_name})\")\n",
        "    try:\n",
        "        # Add the delay BEFORE the API call to space them out\n",
        "        time.sleep(API_DELAY)\n",
        "        # Fetch all available historic ESG ratings for the ticker\n",
        "        esg_scores_df = yesg.get_historic_esg(ticker)\n",
        "\n",
        "        # Check if the result is a non-empty DataFrame\n",
        "        if isinstance(esg_scores_df, pd.DataFrame) and not esg_scores_df.empty:\n",
        "            # Add a column for the ticker symbol\n",
        "            esg_scores_df['Ticker'] = ticker\n",
        "            # Reset the index to make the date a column before appending\n",
        "            # The date column is typically the index after fetching\n",
        "            esg_scores_df = esg_scores_df.reset_index()\n",
        "            # Rename the date column if needed (common names are 'Date' or 'index')\n",
        "            if 'index' in esg_scores_df.columns:\n",
        "                esg_scores_df = esg_scores_df.rename(columns={'index': 'Date'})\n",
        "\n",
        "            all_esg_data_list.append(esg_scores_df)\n",
        "            successful_tickers.append(ticker)\n",
        "            print(f\"    -> Success: Found {len(esg_scores_df)} historic ESG data points for {ticker} ({ticker_name}).\")\n",
        "        else:\n",
        "            # Handle cases where yesg returns None or an empty DataFrame\n",
        "            print(f\"    -> No valid historic ESG data found/returned for {ticker} ({ticker_name}).\")\n",
        "            failed_tickers.append(ticker)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other exceptions during fetching or processing\n",
        "        print(f\"    -> ERROR fetching/processing historic ESG data for {ticker} ({ticker_name}): {e}\")\n",
        "        failed_tickers.append(ticker)\n",
        "\n",
        "# --- Combine and Save Data ---\n",
        "if all_esg_data_list:\n",
        "    print(\"\\nCombining collected historic ESG data...\")\n",
        "    # Concatenate all the collected DataFrames into a single one\n",
        "    final_esg_data = pd.concat(all_esg_data_list, ignore_index=True)\n",
        "\n",
        "    # Ensure the Date column is correctly named and formatted if possible\n",
        "    if 'Date' in final_esg_data.columns:\n",
        "        try:\n",
        "            # Attempt to convert Date column to datetime objects for consistency\n",
        "            final_esg_data['Date'] = pd.to_datetime(final_esg_data['Date'])\n",
        "            # Sort by Ticker and Date for clarity\n",
        "            final_esg_data = final_esg_data.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
        "            print(\"  -> Date column converted to datetime and data sorted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert 'Date' column to datetime format or sort data: {e}\")\n",
        "            print(\"Please inspect the Date column format manually.\")\n",
        "    else:\n",
        "        print(\"Warning: 'Date' column not found in combined data. Please inspect the output DataFrame structure.\")\n",
        "\n",
        "\n",
        "    # Display first few rows and info of the final DataFrame\n",
        "    print(\"\\nPreview of combined historic ESG data:\")\n",
        "    print(final_esg_data.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    final_esg_data.info()\n",
        "    print(f\"\\nTotal rows collected: {len(final_esg_data)}\")\n",
        "\n",
        "\n",
        "    # Save the combined data to the chosen CSV file path\n",
        "    # Check if the save_path variable was set correctly (especially in Colab failure scenario)\n",
        "    if save_path:\n",
        "        try:\n",
        "            print(f\"\\nSaving historic ESG data to: {save_path} ...\")\n",
        "            final_esg_data.to_csv(save_path, index=False)\n",
        "            print(f\"Historic ESG data saved successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR saving historic ESG data to CSV at '{save_path}': {e}\")\n",
        "            if google_colab_available and save_path == OUTPUT_PATH_DRIVE:\n",
        "                print(\"Check if your Google Drive is correctly mounted and you have write permissions.\")\n",
        "    else:\n",
        "         print(\"\\nERROR: Save path was not determined. Cannot save CSV.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    # Message if no data was collected at all\n",
        "    print(\"\\nNo historic ESG data was successfully collected for any ticker. No CSV file created.\")\n",
        "\n",
        "# --- Final Summary ---\n",
        "print(\"\\n--- Historic ESG Fetching Summary ---\")\n",
        "print(f\"Successfully fetched historic ESG data for ({len(successful_tickers)} tickers): {successful_tickers}\")\n",
        "print(f\"Failed or no historic ESG data for ({len(failed_tickers)} tickers): {failed_tickers}\")\n",
        "print(\"--- Script Finished ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 *Fetch ESG Data for Pharma Companies"
      ],
      "metadata": {
        "id": "oApsB25_yY1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries: yesg, pandas\n",
        "# Optional for Google Drive: google.colab\n",
        "# If running locally, you may need to install these:\n",
        "# !pip install yesg pandas\n",
        "\n",
        "import yesg\n",
        "import pandas as pd\n",
        "import time # To add delays between API calls\n",
        "import warnings # To potentially suppress warnings\n",
        "\n",
        "# Attempt to import and use Google Drive specific libraries only if needed\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    google_colab_available = True\n",
        "except ImportError:\n",
        "    google_colab_available = False\n",
        "    print(\"Google Colab environment not detected. Will save CSV locally.\")\n",
        "\n",
        "print(\"--- ESG Data Fetching Script for Pharmaceutical & Healthcare Firms ---\")\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# List of tickers for Pharmaceutical & Healthcare firms\n",
        "# Note: Data availability may vary significantly by ticker and source.\n",
        "TICKERS_PHARMA_HEALTHCARE = [\n",
        "    'LLY',    # Eli Lilly and Company (NYSE)\n",
        "    'JNJ',    # Johnson & Johnson (NYSE)\n",
        "    'MRK',    # Merck & Co. (NYSE)\n",
        "    'NVO',    # Novo Nordisk A/S (NYSE)\n",
        "    'RHHBY',  # Roche Holding AG (OTC)\n",
        "    'PFE',    # Pfizer Inc. (NYSE)\n",
        "    'ABBV',   # AbbVie Inc. (NYSE)\n",
        "    'NVS',    # Novartis AG (NYSE)\n",
        "    'AZN',    # AstraZeneca PLC (NASDAQ/LSE)\n",
        "    'SNY',    # Sanofi (NASDAQ/EPA)\n",
        "    'BMY',    # Bristol Myers Squibb (NYSE)\n",
        "    'GSK',    # GSK plc (NYSE/LSE)\n",
        "    'TAK',    # Takeda Pharmaceutical (NYSE)\n",
        "]\n",
        "\n",
        "# Optional mapping for clearer output\n",
        "TICKER_NAMES = {\n",
        "    'LLY': 'Eli Lilly and Company', 'JNJ': 'Johnson & Johnson',\n",
        "    'MRK': 'Merck & Co.', 'NVO': 'Novo Nordisk A/S',\n",
        "    'RHHBY': 'Roche Holding AG', 'PFE': 'Pfizer Inc.',\n",
        "    'ABBV': 'AbbVie Inc.', 'NVS': 'Novartis AG',\n",
        "    'AZN': 'AstraZeneca PLC', 'SNY': 'Sanofi',\n",
        "    'BMY': 'Bristol Myers Squibb', 'GSK': 'GSK plc',\n",
        "    'TAK': 'Takeda Pharmaceutical',\n",
        "}\n",
        "\n",
        "# Define where to save the output file\n",
        "DRIVE_MOUNT_PATH = '/content/drive'\n",
        "OUTPUT_FILENAME = 'historic_esg_scores_pharma_healthcare.csv'\n",
        "OUTPUT_PATH_DRIVE = f'{DRIVE_MOUNT_PATH}/My Drive/{OUTPUT_FILENAME}' # Standard Google Drive path\n",
        "OUTPUT_PATH_LOCAL = OUTPUT_FILENAME # Save in current directory if Drive fails\n",
        "\n",
        "# Delay between API calls (in seconds) to avoid potential blocking\n",
        "API_DELAY = 0.8 # Slightly increased delay as a precaution\n",
        "\n",
        "# --- Mount Google Drive (if in Colab) ---\n",
        "drive_mounted = False\n",
        "save_path = OUTPUT_PATH_LOCAL # Default save path\n",
        "\n",
        "if google_colab_available:\n",
        "    try:\n",
        "        print(f\"\\nAttempting to mount Google Drive at {DRIVE_MOUNT_PATH}...\")\n",
        "        # Suppress specific warnings that might appear during mounting\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            drive.mount(DRIVE_MOUNT_PATH, force_remount=True) # force_remount=True can help with issues\n",
        "\n",
        "        drive_mounted = True\n",
        "        save_path = OUTPUT_PATH_DRIVE\n",
        "        print(\"Google Drive mounted successfully.\")\n",
        "        print(f\"Output CSV will be saved to Google Drive at '{save_path}'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to mount Google Drive: {e}\")\n",
        "        print(f\"Output CSV will be saved locally as '{OUTPUT_PATH_LOCAL}'.\")\n",
        "else:\n",
        "    # Not in Colab, saving locally\n",
        "    print(f\"\\nOutput CSV will be saved locally as '{OUTPUT_PATH_LOCAL}'.\")\n",
        "\n",
        "\n",
        "# --- Data Fetching Loop ---\n",
        "print(f\"\\nTickers to fetch ESG data for ({len(TICKERS_PHARMA_HEALTHCARE)} total): {TICKERS_PHARMA_HEALTHCARE}\")\n",
        "print(\"Starting ESG data download loop...\")\n",
        "print(\"WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\")\n",
        "print(\"Note: ESG data is typically published annually, so expect one data point per year if available.\")\n",
        "\n",
        "\n",
        "# Initialize lists to store results and track progress\n",
        "all_esg_data_list = []\n",
        "successful_tickers = []\n",
        "failed_tickers = []\n",
        "\n",
        "for ticker in TICKERS_PHARMA_HEALTHCARE:\n",
        "    ticker_name = TICKER_NAMES.get(ticker, ticker) # Use mapped name if available\n",
        "    print(f\"  -> Processing: {ticker} ({ticker_name})\")\n",
        "    try:\n",
        "        # Add the delay BEFORE the API call to space them out\n",
        "        time.sleep(API_DELAY)\n",
        "        # Fetch all available historic ESG ratings for the ticker\n",
        "        esg_scores_df = yesg.get_historic_esg(ticker)\n",
        "\n",
        "        # Check if the result is a non-empty DataFrame\n",
        "        if isinstance(esg_scores_df, pd.DataFrame) and not esg_scores_df.empty:\n",
        "            # Add a column for the ticker symbol\n",
        "            esg_scores_df['Ticker'] = ticker\n",
        "            # Reset the index to make the date a column before appending\n",
        "            # The date column is typically the index after fetching\n",
        "            esg_scores_df = esg_scores_df.reset_index()\n",
        "            # Rename the date column if needed (common names are 'Date' or 'index')\n",
        "            if 'index' in esg_scores_df.columns:\n",
        "                esg_scores_df = esg_scores_df.rename(columns={'index': 'Date'})\n",
        "\n",
        "            all_esg_data_list.append(esg_scores_df)\n",
        "            successful_tickers.append(ticker)\n",
        "            print(f\"    -> Success: Found {len(esg_scores_df)} historic ESG data points for {ticker} ({ticker_name}).\")\n",
        "        else:\n",
        "            # Handle cases where yesg returns None or an empty DataFrame\n",
        "            print(f\"    -> No valid historic ESG data found/returned for {ticker} ({ticker_name}).\")\n",
        "            failed_tickers.append(ticker)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other exceptions during fetching or processing\n",
        "        print(f\"    -> ERROR fetching/processing historic ESG data for {ticker} ({ticker_name}): {e}\")\n",
        "        failed_tickers.append(ticker)\n",
        "\n",
        "# --- Combine and Save Data ---\n",
        "if all_esg_data_list:\n",
        "    print(\"\\nCombining collected historic ESG data...\")\n",
        "    # Concatenate all the collected DataFrames into a single one\n",
        "    final_esg_data = pd.concat(all_esg_data_list, ignore_index=True)\n",
        "\n",
        "    # Ensure the Date column is correctly named and formatted if possible\n",
        "    if 'Date' in final_esg_data.columns:\n",
        "        try:\n",
        "            # Attempt to convert Date column to datetime objects for consistency\n",
        "            final_esg_data['Date'] = pd.to_datetime(final_esg_data['Date'])\n",
        "            # Sort by Ticker and Date for clarity\n",
        "            final_esg_data = final_esg_data.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
        "            print(\"  -> Date column converted to datetime and data sorted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert 'Date' column to datetime format or sort data: {e}\")\n",
        "            print(\"Please inspect the Date column format manually.\")\n",
        "    else:\n",
        "        print(\"Warning: 'Date' column not found in combined data. Please inspect the output DataFrame structure.\")\n",
        "\n",
        "\n",
        "    # Display first few rows and info of the final DataFrame\n",
        "    print(\"\\nPreview of combined historic ESG data:\")\n",
        "    print(final_esg_data.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    final_esg_data.info()\n",
        "    print(f\"\\nTotal rows collected: {len(final_esg_data)}\")\n",
        "\n",
        "\n",
        "    # Save the combined data to the chosen CSV file path\n",
        "    # Check if the save_path variable was set correctly (especially in Colab failure scenario)\n",
        "    if save_path:\n",
        "        try:\n",
        "            print(f\"\\nSaving historic ESG data to: {save_path} ...\")\n",
        "            final_esg_data.to_csv(save_path, index=False)\n",
        "            print(f\"Historic ESG data saved successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nERROR saving historic ESG data to CSV at '{save_path}': {e}\")\n",
        "            if google_colab_available and save_path == OUTPUT_PATH_DRIVE:\n",
        "                print(\"Check if your Google Drive is correctly mounted and you have write permissions.\")\n",
        "    else:\n",
        "         print(\"\\nERROR: Save path was not determined. Cannot save CSV.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    # Message if no data was collected at all\n",
        "    print(\"\\nNo historic ESG data was successfully collected for any ticker. No CSV file created.\")\n",
        "\n",
        "# --- Final Summary ---\n",
        "print(\"\\n--- Historic ESG Fetching Summary ---\")\n",
        "print(f\"Successfully fetched historic ESG data for ({len(successful_tickers)} tickers): {successful_tickers}\")\n",
        "print(f\"Failed or no historic ESG data for ({len(failed_tickers)} tickers): {failed_tickers}\")\n",
        "print(\"--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnlyUqeMykxn",
        "outputId": "2a96c114-0404-4f02-8c02-c3720b2389c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ESG Data Fetching Script for Pharmaceutical & Healthcare Firms ---\n",
            "\n",
            "Attempting to mount Google Drive at /content/drive...\n",
            "Failed to mount Google Drive: mount failed\n",
            "Output CSV will be saved locally as 'historic_esg_scores_pharma_healthcare.csv'.\n",
            "\n",
            "Tickers to fetch ESG data for (13 total): ['LLY', 'JNJ', 'MRK', 'NVO', 'RHHBY', 'PFE', 'ABBV', 'NVS', 'AZN', 'SNY', 'BMY', 'GSK', 'TAK']\n",
            "Starting ESG data download loop...\n",
            "WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\n",
            "Note: ESG data is typically published annually, so expect one data point per year if available.\n",
            "  -> Processing: LLY (Eli Lilly and Company)\n",
            "    -> Success: Found 128 historic ESG data points for LLY (Eli Lilly and Company).\n",
            "  -> Processing: JNJ (Johnson & Johnson)\n",
            "    -> Success: Found 128 historic ESG data points for JNJ (Johnson & Johnson).\n",
            "  -> Processing: MRK (Merck & Co.)\n",
            "    -> Success: Found 128 historic ESG data points for MRK (Merck & Co.).\n",
            "  -> Processing: NVO (Novo Nordisk A/S)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for NVO (Novo Nordisk A/S).\n",
            "  -> Processing: RHHBY (Roche Holding AG)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for RHHBY (Roche Holding AG).\n",
            "  -> Processing: PFE (Pfizer Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for PFE (Pfizer Inc.).\n",
            "  -> Processing: ABBV (AbbVie Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for ABBV (AbbVie Inc.).\n",
            "  -> Processing: NVS (Novartis AG)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for NVS (Novartis AG).\n",
            "  -> Processing: AZN (AstraZeneca PLC)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for AZN (AstraZeneca PLC).\n",
            "  -> Processing: SNY (Sanofi)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for SNY (Sanofi).\n",
            "  -> Processing: BMY (Bristol Myers Squibb)\n",
            "    -> Success: Found 128 historic ESG data points for BMY (Bristol Myers Squibb).\n",
            "  -> Processing: GSK (GSK plc)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for GSK (GSK plc).\n",
            "  -> Processing: TAK (Takeda Pharmaceutical)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for TAK (Takeda Pharmaceutical).\n",
            "\n",
            "Combining collected historic ESG data...\n",
            "  -> Date column converted to datetime and data sorted.\n",
            "\n",
            "Preview of combined historic ESG data:\n",
            "        Date  Total-Score  E-Score  S-Score  G-Score Ticker\n",
            "0 2014-09-01         64.0     66.0     60.0     69.0   ABBV\n",
            "1 2014-10-01         62.0     67.0     57.0     69.0   ABBV\n",
            "2 2014-11-01         66.0     74.0     62.0     66.0   ABBV\n",
            "3 2014-12-01         66.0     74.0     62.0     66.0   ABBV\n",
            "4 2015-01-01         66.0     74.0     62.0     66.0   ABBV\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   Date         768 non-null    datetime64[ns]\n",
            " 1   Total-Score  510 non-null    float64       \n",
            " 2   E-Score      510 non-null    float64       \n",
            " 3   S-Score      510 non-null    float64       \n",
            " 4   G-Score      510 non-null    float64       \n",
            " 5   Ticker       768 non-null    object        \n",
            "dtypes: datetime64[ns](1), float64(4), object(1)\n",
            "memory usage: 36.1+ KB\n",
            "\n",
            "Total rows collected: 768\n",
            "\n",
            "Saving historic ESG data to: historic_esg_scores_pharma_healthcare.csv ...\n",
            "Historic ESG data saved successfully.\n",
            "\n",
            "--- Historic ESG Fetching Summary ---\n",
            "Successfully fetched historic ESG data for (6 tickers): ['LLY', 'JNJ', 'MRK', 'PFE', 'ABBV', 'BMY']\n",
            "Failed or no historic ESG data for (7 tickers): ['NVO', 'RHHBY', 'NVS', 'AZN', 'SNY', 'GSK', 'TAK']\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch Construction Firms ESG Data"
      ],
      "metadata": {
        "id": "DWuRw6Dc4ArH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries: yesg, pandas\n",
        "# If running locally, you need to install these:\n",
        "# !pip install yesg pandas\n",
        "\n",
        "import yesg\n",
        "import pandas as pd\n",
        "import time # To add delays between API calls\n",
        "import warnings # To potentially suppress warnings\n",
        "\n",
        "print(\"--- ESG Data Fetching Script for Civil Construction, Engineering & Materials Firms ---\")\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# List of tickers for Civil Construction, Engineering & Materials firms\n",
        "# Note: Data availability may vary significantly by ticker and source.\n",
        "TICKERS_CONSTRUCTION = [\n",
        "    'DG.PA',  # VINCI SA (Euronext Paris)\n",
        "    'ACS.MC', # ACS Actividades Const. Ser. (Bolsa de Madrid)\n",
        "    'PWR',    # Quanta Services, Inc. (NYSE)\n",
        "    'HCMLY',  # Holcim Ltd. (OTC)\n",
        "    'VMC',    # Vulcan Materials Company (NYSE)\n",
        "    'MLM',    # Martin Marietta Materials (NYSE)\n",
        "    'CRH',    # CRH plc (NYSE/LSE)\n",
        "    'ACM',    # AECOM (NYSE)\n",
        "    'J',      # Jacobs Solutions Inc. (NYSE)\n",
        "    'FLR',    # Fluor Corporation (NYSE)\n",
        "    'MTZ',    # MasTec, Inc. (NYSE)\n",
        "    'HEI.DE', # Heidelberg Materials AG (Frankfurt)\n",
        "    'LT.NS',  # Larsen & Toubro Ltd. (NSE India)\n",
        "]\n",
        "\n",
        "# Optional mapping for clearer output\n",
        "TICKER_NAMES = {\n",
        "    'DG.PA': 'VINCI SA', 'ACS.MC': 'ACS Actividades Const. Ser.',\n",
        "    'PWR': 'Quanta Services, Inc.', 'HCMLY': 'Holcim Ltd.',\n",
        "    'VMC': 'Vulcan Materials Company', 'MLM': 'Martin Marietta Materials',\n",
        "    'CRH': 'CRH plc', 'ACM': 'AECOM', 'J': 'Jacobs Solutions Inc.',\n",
        "    'FLR': 'Fluor Corporation', 'MTZ': 'MasTec, Inc.',\n",
        "    'HEI.DE': 'Heidelberg Materials AG', 'LT.NS': 'Larsen & Toubro Ltd.',\n",
        "}\n",
        "\n",
        "# Define where to save the output file (locally)\n",
        "OUTPUT_FILENAME = 'historic_esg_scores_construction.csv'\n",
        "OUTPUT_PATH_LOCAL = OUTPUT_FILENAME # Save in current directory\n",
        "\n",
        "# Delay between API calls (in seconds) to avoid potential blocking\n",
        "API_DELAY = 0.8 # Slightly increased delay as a precaution\n",
        "\n",
        "# --- Data Fetching Loop ---\n",
        "print(f\"\\nTickers to fetch ESG data for ({len(TICKERS_CONSTRUCTION)} total): {TICKERS_CONSTRUCTION}\")\n",
        "print(\"Starting ESG data download loop...\")\n",
        "print(\"WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\")\n",
        "print(\"Note: ESG data is typically published annually, so expect one data point per year if available.\")\n",
        "\n",
        "\n",
        "# Initialize lists to store results and track progress\n",
        "all_esg_data_list = []\n",
        "successful_tickers = []\n",
        "failed_tickers = []\n",
        "\n",
        "for ticker in TICKERS_CONSTRUCTION:\n",
        "    ticker_name = TICKER_NAMES.get(ticker, ticker) # Use mapped name if available\n",
        "    print(f\"  -> Processing: {ticker} ({ticker_name})\")\n",
        "    try:\n",
        "        # Add the delay BEFORE the API call to space them out\n",
        "        time.sleep(API_DELAY)\n",
        "        # Fetch all available historic ESG ratings for the ticker\n",
        "        esg_scores_df = yesg.get_historic_esg(ticker)\n",
        "\n",
        "        # Check if the result is a non-empty DataFrame\n",
        "        if isinstance(esg_scores_df, pd.DataFrame) and not esg_scores_df.empty:\n",
        "            # Add a column for the ticker symbol\n",
        "            esg_scores_df['Ticker'] = ticker\n",
        "            # Reset the index to make the date a column before appending\n",
        "            # The date column is typically the index after fetching\n",
        "            esg_scores_df = esg_scores_df.reset_index()\n",
        "            # Rename the date column if needed (common names are 'Date' or 'index')\n",
        "            if 'index' in esg_scores_df.columns:\n",
        "                esg_scores_df = esg_scores_df.rename(columns={'index': 'Date'})\n",
        "\n",
        "            all_esg_data_list.append(esg_scores_df)\n",
        "            successful_tickers.append(ticker)\n",
        "            print(f\"    -> Success: Found {len(esg_scores_df)} historic ESG data points for {ticker} ({ticker_name}).\")\n",
        "        else:\n",
        "            # Handle cases where yesg returns None or an empty DataFrame\n",
        "            print(f\"    -> No valid historic ESG data found/returned for {ticker} ({ticker_name}).\")\n",
        "            failed_tickers.append(ticker)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other exceptions during fetching or processing\n",
        "        print(f\"    -> ERROR fetching/processing historic ESG data for {ticker} ({ticker_name}): {e}\")\n",
        "        failed_tickers.append(ticker)\n",
        "\n",
        "# --- Combine and Save Data ---\n",
        "if all_esg_data_list:\n",
        "    print(\"\\nCombining collected historic ESG data...\")\n",
        "    # Concatenate all the collected DataFrames into a single one\n",
        "    final_esg_data = pd.concat(all_esg_data_list, ignore_index=True)\n",
        "\n",
        "    # Ensure the Date column is correctly named and formatted if possible\n",
        "    if 'Date' in final_esg_data.columns:\n",
        "        try:\n",
        "            # Attempt to convert Date column to datetime objects for consistency\n",
        "            final_esg_data['Date'] = pd.to_datetime(final_esg_data['Date'])\n",
        "            # Sort by Ticker and Date for clarity\n",
        "            final_esg_data = final_esg_data.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
        "            print(\"  -> Date column converted to datetime and data sorted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert 'Date' column to datetime format or sort data: {e}\")\n",
        "            print(\"Please inspect the Date column format manually.\")\n",
        "    else:\n",
        "        print(\"Warning: 'Date' column not found in combined data. Please inspect the output DataFrame structure.\")\n",
        "\n",
        "\n",
        "    # Display first few rows and info of the final DataFrame\n",
        "    print(\"\\nPreview of combined historic ESG data:\")\n",
        "    print(final_esg_data.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    final_esg_data.info()\n",
        "    print(f\"\\nTotal rows collected: {len(final_esg_data)}\")\n",
        "\n",
        "\n",
        "    # Save the combined data to the chosen CSV file path (local)\n",
        "    try:\n",
        "        print(f\"\\nSaving historic ESG data to: {OUTPUT_PATH_LOCAL} ...\")\n",
        "        final_esg_data.to_csv(OUTPUT_PATH_LOCAL, index=False)\n",
        "        print(f\"Historic ESG data saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR saving historic ESG data to CSV at '{OUTPUT_PATH_LOCAL}': {e}\")\n",
        "\n",
        "\n",
        "else:\n",
        "    # Message if no data was collected at all\n",
        "    print(\"\\nNo historic ESG data was successfully collected for any ticker. No CSV file created.\")\n",
        "\n",
        "# --- Final Summary ---\n",
        "print(\"\\n--- Historic ESG Fetching Summary ---\")\n",
        "print(f\"Successfully fetched historic ESG data for ({len(successful_tickers)} tickers): {successful_tickers}\")\n",
        "print(f\"Failed or no historic ESG data for ({len(failed_tickers)} tickers): {failed_tickers}\")\n",
        "print(\"--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Mnj4pA4H-J",
        "outputId": "6902186b-34c0-466d-d7db-db2a739c7c59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ESG Data Fetching Script for Civil Construction, Engineering & Materials Firms ---\n",
            "\n",
            "Tickers to fetch ESG data for (13 total): ['DG.PA', 'ACS.MC', 'PWR', 'HCMLY', 'VMC', 'MLM', 'CRH', 'ACM', 'J', 'FLR', 'MTZ', 'HEI.DE', 'LT.NS']\n",
            "Starting ESG data download loop...\n",
            "WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\n",
            "Note: ESG data is typically published annually, so expect one data point per year if available.\n",
            "  -> Processing: DG.PA (VINCI SA)\n",
            "    -> Success: Found 128 historic ESG data points for DG.PA (VINCI SA).\n",
            "  -> Processing: ACS.MC (ACS Actividades Const. Ser.)\n",
            "    -> Success: Found 128 historic ESG data points for ACS.MC (ACS Actividades Const. Ser.).\n",
            "  -> Processing: PWR (Quanta Services, Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for PWR (Quanta Services, Inc.).\n",
            "  -> Processing: HCMLY (Holcim Ltd.)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for HCMLY (Holcim Ltd.).\n",
            "  -> Processing: VMC (Vulcan Materials Company)\n",
            "    -> Success: Found 128 historic ESG data points for VMC (Vulcan Materials Company).\n",
            "  -> Processing: MLM (Martin Marietta Materials)\n",
            "    -> Success: Found 128 historic ESG data points for MLM (Martin Marietta Materials).\n",
            "  -> Processing: CRH (CRH plc)\n",
            "    -> Success: Found 6 historic ESG data points for CRH (CRH plc).\n",
            "  -> Processing: ACM (AECOM)\n",
            "    -> Success: Found 128 historic ESG data points for ACM (AECOM).\n",
            "  -> Processing: J (Jacobs Solutions Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for J (Jacobs Solutions Inc.).\n",
            "  -> Processing: FLR (Fluor Corporation)\n",
            "    -> Success: Found 128 historic ESG data points for FLR (Fluor Corporation).\n",
            "  -> Processing: MTZ (MasTec, Inc.)\n",
            "    -> Success: Found 6 historic ESG data points for MTZ (MasTec, Inc.).\n",
            "  -> Processing: HEI.DE (Heidelberg Materials AG)\n",
            "    -> Success: Found 128 historic ESG data points for HEI.DE (Heidelberg Materials AG).\n",
            "  -> Processing: LT.NS (Larsen & Toubro Ltd.)\n",
            "    -> Success: Found 109 historic ESG data points for LT.NS (Larsen & Toubro Ltd.).\n",
            "\n",
            "Combining collected historic ESG data...\n",
            "  -> Date column converted to datetime and data sorted.\n",
            "\n",
            "Preview of combined historic ESG data:\n",
            "        Date  Total-Score  E-Score  S-Score  G-Score Ticker\n",
            "0 2014-09-01         60.0     56.0     54.0     74.0    ACM\n",
            "1 2014-10-01         60.0     56.0     54.0     74.0    ACM\n",
            "2 2014-11-01         60.0     56.0     54.0     74.0    ACM\n",
            "3 2014-12-01         60.0     56.0     54.0     74.0    ACM\n",
            "4 2015-01-01         59.0     56.0     51.0     73.0    ACM\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1273 entries, 0 to 1272\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   Date         1273 non-null   datetime64[ns]\n",
            " 1   Total-Score  863 non-null    float64       \n",
            " 2   E-Score      863 non-null    float64       \n",
            " 3   S-Score      863 non-null    float64       \n",
            " 4   G-Score      863 non-null    float64       \n",
            " 5   Ticker       1273 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(4), object(1)\n",
            "memory usage: 59.8+ KB\n",
            "\n",
            "Total rows collected: 1273\n",
            "\n",
            "Saving historic ESG data to: historic_esg_scores_construction.csv ...\n",
            "Historic ESG data saved successfully.\n",
            "\n",
            "--- Historic ESG Fetching Summary ---\n",
            "Successfully fetched historic ESG data for (12 tickers): ['DG.PA', 'ACS.MC', 'PWR', 'VMC', 'MLM', 'CRH', 'ACM', 'J', 'FLR', 'MTZ', 'HEI.DE', 'LT.NS']\n",
            "Failed or no historic ESG data for (1 tickers): ['HCMLY']\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch Crtical Earth Material - Mining ESG Data"
      ],
      "metadata": {
        "id": "cYsz--q045YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries: yesg, pandas\n",
        "# If running locally, you need to install these:\n",
        "# !pip install yesg pandas\n",
        "\n",
        "import yesg\n",
        "import pandas as pd\n",
        "import time # To add delays between API calls\n",
        "import warnings # To potentially suppress warnings\n",
        "\n",
        "print(\"--- ESG Data Fetching Script for Critical Materials, Mining & Rare Earths Firms ---\")\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# List of tickers for Critical Materials, Mining & Rare Earths firms\n",
        "# Note: Data availability may vary significantly by ticker and source.\n",
        "TICKERS_MINING_RE = [\n",
        "    'BHP',    # BHP Group Ltd. (NYSE/ASX/LSE) - Using NYSE\n",
        "    'RIO',    # Rio Tinto Group (NYSE/ASX/LSE) - Using NYSE\n",
        "    'VALE',   # Vale S.A. (NYSE)\n",
        "    'GLNCY',  # Glencore plc (OTC) - Using OTC for simplicity\n",
        "    'FCX',    # Freeport-McMoRan Inc. (NYSE)\n",
        "    'ALB',    # Albemarle Corporation (NYSE)\n",
        "    'SQM',    # SQM (Soc. Química Minera) (NYSE)\n",
        "    'MP',     # MP Materials Corp. (NYSE)\n",
        "    'LYSCF',  # Lynas Rare Earths Ltd. (OTC) - Using OTC for simplicity\n",
        "    'LAC',    # Lithium Americas Corp. (NYSE/TSX) - Using NYSE\n",
        "    'ALTM',   # Arcadium Lithium plc (NYSE)\n",
        "    'SGML',   # Sigma Lithium Corp. (NASDAQ/TSXV) - Using NASDAQ\n",
        "    'UUUU',   # Energy Fuels Inc. (NYSEAM/TSX) - Using NYSEAM\n",
        "    'ILKAF',  # Iluka Resources Ltd. (OTC) - Using OTC for simplicity\n",
        "    'PILBF',  # Pilbara Minerals Ltd. (OTC) - Using OTC for simplicity\n",
        "]\n",
        "\n",
        "# Optional mapping for clearer output\n",
        "TICKER_NAMES = {\n",
        "    'BHP': 'BHP Group Ltd.', 'RIO': 'Rio Tinto Group', 'VALE': 'Vale S.A.',\n",
        "    'GLNCY': 'Glencore plc', 'FCX': 'Freeport-McMoRan Inc.', 'ALB': 'Albemarle Corporation',\n",
        "    'SQM': 'SQM (Soc. Química Minera)', 'MP': 'MP Materials Corp.',\n",
        "    'LYSCF': 'Lynas Rare Earths Ltd.', 'LAC': 'Lithium Americas Corp.',\n",
        "    'ALTM': 'Arcadium Lithium plc', 'SGML': 'Sigma Lithium Corp.',\n",
        "    'UUUU': 'Energy Fuels Inc.', 'ILKAF': 'Iluka Resources Ltd.',\n",
        "    'PILBF': 'Pilbara Minerals Ltd.',\n",
        "}\n",
        "\n",
        "# Define where to save the output file (locally)\n",
        "OUTPUT_FILENAME = 'historic_esg_scores_mining_re.csv'\n",
        "OUTPUT_PATH_LOCAL = OUTPUT_FILENAME # Save in current directory\n",
        "\n",
        "# Delay between API calls (in seconds) to avoid potential blocking\n",
        "API_DELAY = 0.8 # Slightly increased delay as a precaution\n",
        "\n",
        "# --- Data Fetching Loop ---\n",
        "print(f\"\\nTickers to fetch ESG data for ({len(TICKERS_MINING_RE)} total): {TICKERS_MINING_RE}\")\n",
        "print(\"Starting ESG data download loop...\")\n",
        "print(\"WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\")\n",
        "print(\"Note: ESG data is typically published annually, so expect one data point per year if available.\")\n",
        "\n",
        "\n",
        "# Initialize lists to store results and track progress\n",
        "all_esg_data_list = []\n",
        "successful_tickers = []\n",
        "failed_tickers = []\n",
        "\n",
        "for ticker in TICKERS_MINING_RE:\n",
        "    ticker_name = TICKER_NAMES.get(ticker, ticker) # Use mapped name if available\n",
        "    print(f\"  -> Processing: {ticker} ({ticker_name})\")\n",
        "    try:\n",
        "        # Add the delay BEFORE the API call to space them out\n",
        "        time.sleep(API_DELAY)\n",
        "        # Fetch all available historic ESG ratings for the ticker\n",
        "        esg_scores_df = yesg.get_historic_esg(ticker)\n",
        "\n",
        "        # Check if the result is a non-empty DataFrame\n",
        "        if isinstance(esg_scores_df, pd.DataFrame) and not esg_scores_df.empty:\n",
        "            # Add a column for the ticker symbol\n",
        "            esg_scores_df['Ticker'] = ticker\n",
        "            # Reset the index to make the date a column before appending\n",
        "            # The date column is typically the index after fetching\n",
        "            esg_scores_df = esg_scores_df.reset_index()\n",
        "            # Rename the date column if needed (common names are 'Date' or 'index')\n",
        "            if 'index' in esg_scores_df.columns:\n",
        "                esg_scores_df = esg_scores_df.rename(columns={'index': 'Date'})\n",
        "\n",
        "            all_esg_data_list.append(esg_scores_df)\n",
        "            successful_tickers.append(ticker)\n",
        "            print(f\"    -> Success: Found {len(esg_scores_df)} historic ESG data points for {ticker} ({ticker_name}).\")\n",
        "        else:\n",
        "            # Handle cases where yesg returns None or an empty DataFrame\n",
        "            print(f\"    -> No valid historic ESG data found/returned for {ticker} ({ticker_name}).\")\n",
        "            failed_tickers.append(ticker)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other exceptions during fetching or processing\n",
        "        print(f\"    -> ERROR fetching/processing historic ESG data for {ticker} ({ticker_name}): {e}\")\n",
        "        failed_tickers.append(ticker)\n",
        "\n",
        "# --- Combine and Save Data ---\n",
        "if all_esg_data_list:\n",
        "    print(\"\\nCombining collected historic ESG data...\")\n",
        "    # Concatenate all the collected DataFrames into a single one\n",
        "    final_esg_data = pd.concat(all_esg_data_list, ignore_index=True)\n",
        "\n",
        "    # Ensure the Date column is correctly named and formatted if possible\n",
        "    if 'Date' in final_esg_data.columns:\n",
        "        try:\n",
        "            # Attempt to convert Date column to datetime objects for consistency\n",
        "            final_esg_data['Date'] = pd.to_datetime(final_esg_data['Date'])\n",
        "            # Sort by Ticker and Date for clarity\n",
        "            final_esg_data = final_esg_data.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
        "            print(\"  -> Date column converted to datetime and data sorted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert 'Date' column to datetime format or sort data: {e}\")\n",
        "            print(\"Please inspect the Date column format manually.\")\n",
        "    else:\n",
        "        print(\"Warning: 'Date' column not found in combined data. Please inspect the output DataFrame structure.\")\n",
        "\n",
        "\n",
        "    # Display first few rows and info of the final DataFrame\n",
        "    print(\"\\nPreview of combined historic ESG data:\")\n",
        "    print(final_esg_data.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    final_esg_data.info()\n",
        "    print(f\"\\nTotal rows collected: {len(final_esg_data)}\")\n",
        "\n",
        "\n",
        "    # Save the combined data to the chosen CSV file path (local)\n",
        "    try:\n",
        "        print(f\"\\nSaving historic ESG data to: {OUTPUT_PATH_LOCAL} ...\")\n",
        "        final_esg_data.to_csv(OUTPUT_PATH_LOCAL, index=False)\n",
        "        print(f\"Historic ESG data saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR saving historic ESG data to CSV at '{OUTPUT_PATH_LOCAL}': {e}\")\n",
        "\n",
        "\n",
        "else:\n",
        "    # Message if no data was collected at all\n",
        "    print(\"\\nNo historic ESG data was successfully collected for any ticker. No CSV file created.\")\n",
        "\n",
        "# --- Final Summary ---\n",
        "print(\"\\n--- Historic ESG Fetching Summary ---\")\n",
        "print(f\"Successfully fetched historic ESG data for ({len(successful_tickers)} tickers): {successful_tickers}\")\n",
        "print(f\"Failed or no historic ESG data for ({len(failed_tickers)} tickers): {failed_tickers}\")\n",
        "print(\"--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUAEungk5Ee-",
        "outputId": "c2f674fb-f873-4bf1-aa7b-33624c1c9a39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ESG Data Fetching Script for Critical Materials, Mining & Rare Earths Firms ---\n",
            "\n",
            "Tickers to fetch ESG data for (15 total): ['BHP', 'RIO', 'VALE', 'GLNCY', 'FCX', 'ALB', 'SQM', 'MP', 'LYSCF', 'LAC', 'ALTM', 'SGML', 'UUUU', 'ILKAF', 'PILBF']\n",
            "Starting ESG data download loop...\n",
            "WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\n",
            "Note: ESG data is typically published annually, so expect one data point per year if available.\n",
            "  -> Processing: BHP (BHP Group Ltd.)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for BHP (BHP Group Ltd.).\n",
            "  -> Processing: RIO (Rio Tinto Group)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for RIO (Rio Tinto Group).\n",
            "  -> Processing: VALE (Vale S.A.)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for VALE (Vale S.A.).\n",
            "  -> Processing: GLNCY (Glencore plc)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for GLNCY (Glencore plc).\n",
            "  -> Processing: FCX (Freeport-McMoRan Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for FCX (Freeport-McMoRan Inc.).\n",
            "  -> Processing: ALB (Albemarle Corporation)\n",
            "    -> Success: Found 128 historic ESG data points for ALB (Albemarle Corporation).\n",
            "  -> Processing: SQM (SQM (Soc. Química Minera))\n",
            "    -> Success: Found 128 historic ESG data points for SQM (SQM (Soc. Química Minera)).\n",
            "  -> Processing: MP (MP Materials Corp.)\n",
            "    -> Success: Found 6 historic ESG data points for MP (MP Materials Corp.).\n",
            "  -> Processing: LYSCF (Lynas Rare Earths Ltd.)\n",
            "    -> Success: Found 6 historic ESG data points for LYSCF (Lynas Rare Earths Ltd.).\n",
            "  -> Processing: LAC (Lithium Americas Corp.)\n",
            "    -> Success: Found 6 historic ESG data points for LAC (Lithium Americas Corp.).\n",
            "  -> Processing: ALTM (Arcadium Lithium plc)\n",
            "    -> Success: Found 3 historic ESG data points for ALTM (Arcadium Lithium plc).\n",
            "  -> Processing: SGML (Sigma Lithium Corp.)\n",
            "    -> Success: Found 7 historic ESG data points for SGML (Sigma Lithium Corp.).\n",
            "  -> Processing: UUUU (Energy Fuels Inc.)\n",
            "    -> Success: Found 7 historic ESG data points for UUUU (Energy Fuels Inc.).\n",
            "  -> Processing: ILKAF (Iluka Resources Ltd.)\n",
            "    -> Success: Found 6 historic ESG data points for ILKAF (Iluka Resources Ltd.).\n",
            "  -> Processing: PILBF (Pilbara Minerals Ltd.)\n",
            "    -> Success: Found 6 historic ESG data points for PILBF (Pilbara Minerals Ltd.).\n",
            "\n",
            "Combining collected historic ESG data...\n",
            "  -> Date column converted to datetime and data sorted.\n",
            "\n",
            "Preview of combined historic ESG data:\n",
            "        Date  Total-Score  E-Score  S-Score  G-Score Ticker\n",
            "0 2014-09-01         68.0     57.0     71.0     81.0    ALB\n",
            "1 2014-10-01         67.0     57.0     71.0     81.0    ALB\n",
            "2 2014-11-01         67.0     57.0     71.0     79.0    ALB\n",
            "3 2014-12-01         67.0     57.0     71.0     79.0    ALB\n",
            "4 2015-01-01         65.0     54.0     67.0     80.0    ALB\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 431 entries, 0 to 430\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   Date         431 non-null    datetime64[ns]\n",
            " 1   Total-Score  269 non-null    float64       \n",
            " 2   E-Score      269 non-null    float64       \n",
            " 3   S-Score      269 non-null    float64       \n",
            " 4   G-Score      269 non-null    float64       \n",
            " 5   Ticker       431 non-null    object        \n",
            "dtypes: datetime64[ns](1), float64(4), object(1)\n",
            "memory usage: 20.3+ KB\n",
            "\n",
            "Total rows collected: 431\n",
            "\n",
            "Saving historic ESG data to: historic_esg_scores_mining_re.csv ...\n",
            "Historic ESG data saved successfully.\n",
            "\n",
            "--- Historic ESG Fetching Summary ---\n",
            "Successfully fetched historic ESG data for (11 tickers): ['FCX', 'ALB', 'SQM', 'MP', 'LYSCF', 'LAC', 'ALTM', 'SGML', 'UUUU', 'ILKAF', 'PILBF']\n",
            "Failed or no historic ESG data for (4 tickers): ['BHP', 'RIO', 'VALE', 'GLNCY']\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regression and Panel Regression Python code"
      ],
      "metadata": {
        "id": "OMV8oabHZARN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3* Fetch Electronics Firm's ESG Data"
      ],
      "metadata": {
        "id": "mzwJUhdH79uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries: yesg, pandas\n",
        "# If running locally, you need to install these:\n",
        "# !pip install yesg pandas\n",
        "\n",
        "import yesg\n",
        "import pandas as pd\n",
        "import time # To add delays between API calls\n",
        "import warnings # To potentially suppress warnings\n",
        "\n",
        "print(\"--- ESG Data Fetching Script for Global Electronic Manufacturers ---\")\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# List of tickers for Global Electronic Manufacturers\n",
        "# Prioritizing major US exchanges (NASDAQ, NYSE) or primary local ones if available via Yahoo Finance\n",
        "# Note: Data availability may vary significantly by ticker and source.\n",
        "TICKERS_ELECTRONICS = [\n",
        "    'AAPL',   # Apple Inc. (NASDAQ)\n",
        "    '005930.KS', # Samsung Electronics (KRX) - Yahoo Finance often uses .KS\n",
        "    'SONY',   # Sony Group Corporation (NYSE) - Using NYSE ticker\n",
        "    '6752.T', # Panasonic Holdings (TSE) - Using TSE ticker\n",
        "    '066570.KS',# LG Electronics (KRX) - Yahoo Finance often uses .KS\n",
        "    '2317.TW',# Foxconn (Hon Hai) (TPE) - Yahoo Finance often uses .TW\n",
        "    'PHG',    # Philips (NYSE) - Using NYSE ticker\n",
        "    'SIEGY',  # Siemens AG (OTC) - Using OTC for simplicity\n",
        "    'CAJ',    # Canon Inc. (NYSE) - Using NYSE ticker\n",
        "    '6753.T', # Sharp Corporation (TSE) - Using TSE ticker\n",
        "    'TXN',    # Texas Instruments (NASDAQ)\n",
        "    'INTC',   # Intel Corporation (NASDAQ)\n",
        "    'NXPI',   # NXP Semiconductors (NASDAQ)\n",
        "    'STM',    # STMicroelectronics (NYSE) - Using NYSE ticker\n",
        "    'IFX.DE', # Infineon Technologies (FWB) - Using FWB ticker\n",
        "    'ASML',   # ASML Holding (NASDAQ) - Using NASDAQ ticker\n",
        "    'MU',     # Micron Technology (NASDAQ)\n",
        "    'ADI',    # Analog Devices (NASDAQ)\n",
        "    'AVGO',   # Broadcom Inc. (NASDAQ)\n",
        "    '6502.T', # Toshiba Corporation (TSE) - Using TSE ticker\n",
        "]\n",
        "\n",
        "# Optional mapping for clearer output\n",
        "TICKER_NAMES = {\n",
        "    'AAPL': 'Apple Inc.', '005930.KS': 'Samsung Electronics', 'SONY': 'Sony Group Corporation',\n",
        "    '6752.T': 'Panasonic Holdings', '066570.KS': 'LG Electronics', '2317.TW': 'Foxconn (Hon Hai)',\n",
        "    'PHG': 'Philips', 'SIEGY': 'Siemens AG', 'CAJ': 'Canon Inc.', '6753.T': 'Sharp Corporation',\n",
        "    'TXN': 'Texas Instruments', 'INTC': 'Intel Corporation', 'NXPI': 'NXP Semiconductors',\n",
        "    'STM': 'STMicroelectronics', 'IFX.DE': 'Infineon Technologies', 'ASML': 'ASML Holding',\n",
        "    'MU': 'Micron Technology', 'ADI': 'Analog Devices', 'AVGO': 'Broadcom Inc.',\n",
        "    '6502.T': 'Toshiba Corporation',\n",
        "}\n",
        "\n",
        "# Define where to save the output file (locally)\n",
        "OUTPUT_FILENAME = 'historic_esg_scores_electronics.csv'\n",
        "OUTPUT_PATH_LOCAL = OUTPUT_FILENAME # Save in current directory\n",
        "\n",
        "# Delay between API calls (in seconds) to avoid potential blocking\n",
        "API_DELAY = 0.8 # Slightly increased delay as a precaution\n",
        "\n",
        "# --- Data Fetching Loop ---\n",
        "print(f\"\\nTickers to fetch ESG data for ({len(TICKERS_ELECTRONICS)} total): {TICKERS_ELECTRONICS}\")\n",
        "print(\"Starting ESG data download loop...\")\n",
        "print(\"WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\")\n",
        "print(\"Note: ESG data is typically published annually, so expect one data point per year if available.\")\n",
        "\n",
        "\n",
        "# Initialize lists to store results and track progress\n",
        "all_esg_data_list = []\n",
        "successful_tickers = []\n",
        "failed_tickers = []\n",
        "\n",
        "for ticker in TICKERS_ELECTRONICS:\n",
        "    ticker_name = TICKER_NAMES.get(ticker, ticker) # Use mapped name if available\n",
        "    print(f\"  -> Processing: {ticker} ({ticker_name})\")\n",
        "    try:\n",
        "        # Add the delay BEFORE the API call to space them out\n",
        "        time.sleep(API_DELAY)\n",
        "        # Fetch all available historic ESG ratings for the ticker\n",
        "        esg_scores_df = yesg.get_historic_esg(ticker)\n",
        "\n",
        "        # Check if the result is a non-empty DataFrame\n",
        "        if isinstance(esg_scores_df, pd.DataFrame) and not esg_scores_df.empty:\n",
        "            # Add a column for the ticker symbol\n",
        "            esg_scores_df['Ticker'] = ticker\n",
        "            # Reset the index to make the date a column before appending\n",
        "            # The date column is typically the index after fetching\n",
        "            esg_scores_df = esg_scores_df.reset_index()\n",
        "            # Rename the date column if needed (common names are 'Date' or 'index')\n",
        "            if 'index' in esg_scores_df.columns:\n",
        "                esg_scores_df = esg_scores_df.rename(columns={'index': 'Date'})\n",
        "\n",
        "            all_esg_data_list.append(esg_scores_df)\n",
        "            successful_tickers.append(ticker)\n",
        "            print(f\"    -> Success: Found {len(esg_scores_df)} historic ESG data points for {ticker} ({ticker_name}).\")\n",
        "        else:\n",
        "            # Handle cases where yesg returns None or an empty DataFrame\n",
        "            print(f\"    -> No valid historic ESG data found/returned for {ticker} ({ticker_name}).\")\n",
        "            failed_tickers.append(ticker)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any other exceptions during fetching or processing\n",
        "        print(f\"    -> ERROR fetching/processing historic ESG data for {ticker} ({ticker_name}): {e}\")\n",
        "        failed_tickers.append(ticker)\n",
        "\n",
        "# --- Combine and Save Data ---\n",
        "if all_esg_data_list:\n",
        "    print(\"\\nCombining collected historic ESG data...\")\n",
        "    # Concatenate all the collected DataFrames into a single one\n",
        "    final_esg_data = pd.concat(all_esg_data_list, ignore_index=True)\n",
        "\n",
        "    # Ensure the Date column is correctly named and formatted if possible\n",
        "    if 'Date' in final_esg_data.columns:\n",
        "        try:\n",
        "            # Attempt to convert Date column to datetime objects for consistency\n",
        "            final_esg_data['Date'] = pd.to_datetime(final_esg_data['Date'])\n",
        "            # Sort by Ticker and Date for clarity\n",
        "            final_esg_data = final_esg_data.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
        "            print(\"  -> Date column converted to datetime and data sorted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert 'Date' column to datetime format or sort data: {e}\")\n",
        "            print(\"Please inspect the Date column format manually.\")\n",
        "    else:\n",
        "        print(\"Warning: 'Date' column not found in combined data. Please inspect the output DataFrame structure.\")\n",
        "\n",
        "\n",
        "    # Display first few rows and info of the final DataFrame\n",
        "    print(\"\\nPreview of combined historic ESG data:\")\n",
        "    print(final_esg_data.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    final_esg_data.info()\n",
        "    print(f\"\\nTotal rows collected: {len(final_esg_data)}\")\n",
        "\n",
        "\n",
        "    # Save the combined data to the chosen CSV file path (local)\n",
        "    try:\n",
        "        print(f\"\\nSaving historic ESG data to: {OUTPUT_PATH_LOCAL} ...\")\n",
        "        final_esg_data.to_csv(OUTPUT_PATH_LOCAL, index=False)\n",
        "        print(f\"Historic ESG data saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR saving historic ESG data to CSV at '{OUTPUT_PATH_LOCAL}': {e}\")\n",
        "\n",
        "\n",
        "else:\n",
        "    # Message if no data was collected at all\n",
        "    print(\"\\nNo historic ESG data was successfully collected for any ticker. No CSV file created.\")\n",
        "\n",
        "# --- Final Summary ---\n",
        "print(\"\\n--- Historic ESG Fetching Summary ---\")\n",
        "print(f\"Successfully fetched historic ESG data for ({len(successful_tickers)} tickers): {successful_tickers}\")\n",
        "print(f\"Failed or no historic ESG data for ({len(failed_tickers)} tickers): {failed_tickers}\")\n",
        "print(\"--- Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3Bkqn9I8HQP",
        "outputId": "1dd7cc96-e64b-446e-cd12-094a2bbcd95c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ESG Data Fetching Script for Global Electronic Manufacturers ---\n",
            "\n",
            "Tickers to fetch ESG data for (20 total): ['AAPL', '005930.KS', 'SONY', '6752.T', '066570.KS', '2317.TW', 'PHG', 'SIEGY', 'CAJ', '6753.T', 'TXN', 'INTC', 'NXPI', 'STM', 'IFX.DE', 'ASML', 'MU', 'ADI', 'AVGO', '6502.T']\n",
            "Starting ESG data download loop...\n",
            "WARNING: 'yesg' library relies on Yahoo Finance and may be outdated or have limited data coverage.\n",
            "Note: ESG data is typically published annually, so expect one data point per year if available.\n",
            "  -> Processing: AAPL (Apple Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for AAPL (Apple Inc.).\n",
            "  -> Processing: 005930.KS (Samsung Electronics)\n",
            "    -> Success: Found 109 historic ESG data points for 005930.KS (Samsung Electronics).\n",
            "  -> Processing: SONY (Sony Group Corporation)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for SONY (Sony Group Corporation).\n",
            "  -> Processing: 6752.T (Panasonic Holdings)\n",
            "    -> Success: Found 128 historic ESG data points for 6752.T (Panasonic Holdings).\n",
            "  -> Processing: 066570.KS (LG Electronics)\n",
            "    -> Success: Found 109 historic ESG data points for 066570.KS (LG Electronics).\n",
            "  -> Processing: 2317.TW (Foxconn (Hon Hai))\n",
            "    -> Success: Found 109 historic ESG data points for 2317.TW (Foxconn (Hon Hai)).\n",
            "  -> Processing: PHG (Philips)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for PHG (Philips).\n",
            "  -> Processing: SIEGY (Siemens AG)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for SIEGY (Siemens AG).\n",
            "  -> Processing: CAJ (Canon Inc.)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for CAJ (Canon Inc.).\n",
            "  -> Processing: 6753.T (Sharp Corporation)\n",
            "    -> Success: Found 128 historic ESG data points for 6753.T (Sharp Corporation).\n",
            "  -> Processing: TXN (Texas Instruments)\n",
            "    -> Success: Found 128 historic ESG data points for TXN (Texas Instruments).\n",
            "  -> Processing: INTC (Intel Corporation)\n",
            "    -> Success: Found 128 historic ESG data points for INTC (Intel Corporation).\n",
            "  -> Processing: NXPI (NXP Semiconductors)\n",
            "    -> Success: Found 128 historic ESG data points for NXPI (NXP Semiconductors).\n",
            "  -> Processing: STM (STMicroelectronics)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for STM (STMicroelectronics).\n",
            "  -> Processing: IFX.DE (Infineon Technologies)\n",
            "    -> Success: Found 128 historic ESG data points for IFX.DE (Infineon Technologies).\n",
            "  -> Processing: ASML (ASML Holding)\n",
            "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
            "    -> No valid historic ESG data found/returned for ASML (ASML Holding).\n",
            "  -> Processing: MU (Micron Technology)\n",
            "    -> Success: Found 128 historic ESG data points for MU (Micron Technology).\n",
            "  -> Processing: ADI (Analog Devices)\n",
            "    -> Success: Found 128 historic ESG data points for ADI (Analog Devices).\n",
            "  -> Processing: AVGO (Broadcom Inc.)\n",
            "    -> Success: Found 128 historic ESG data points for AVGO (Broadcom Inc.).\n",
            "  -> Processing: 6502.T (Toshiba Corporation)\n",
            "    -> Success: Found 109 historic ESG data points for 6502.T (Toshiba Corporation).\n",
            "\n",
            "Combining collected historic ESG data...\n",
            "  -> Date column converted to datetime and data sorted.\n",
            "\n",
            "Preview of combined historic ESG data:\n",
            "        Date  Total-Score  E-Score  S-Score  G-Score     Ticker\n",
            "0 2014-09-01         71.0     90.0     58.0     58.0  005930.KS\n",
            "1 2014-10-01         69.0     90.0     58.0     58.0  005930.KS\n",
            "2 2014-11-01         71.0     90.0     58.0     58.0  005930.KS\n",
            "3 2014-12-01         71.0     90.0     58.0     58.0  005930.KS\n",
            "4 2015-01-01         71.0     90.0     58.0     58.0  005930.KS\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1716 entries, 0 to 1715\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   Date         1716 non-null   datetime64[ns]\n",
            " 1   Total-Score  1175 non-null   float64       \n",
            " 2   E-Score      1175 non-null   float64       \n",
            " 3   S-Score      1175 non-null   float64       \n",
            " 4   G-Score      1175 non-null   float64       \n",
            " 5   Ticker       1716 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(4), object(1)\n",
            "memory usage: 80.6+ KB\n",
            "\n",
            "Total rows collected: 1716\n",
            "\n",
            "Saving historic ESG data to: historic_esg_scores_electronics.csv ...\n",
            "Historic ESG data saved successfully.\n",
            "\n",
            "--- Historic ESG Fetching Summary ---\n",
            "Successfully fetched historic ESG data for (14 tickers): ['AAPL', '005930.KS', '6752.T', '066570.KS', '2317.TW', '6753.T', 'TXN', 'INTC', 'NXPI', 'IFX.DE', 'MU', 'ADI', 'AVGO', '6502.T']\n",
            "Failed or no historic ESG data for (6 tickers): ['SONY', 'PHG', 'SIEGY', 'CAJ', 'STM', 'ASML']\n",
            "--- Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transportation Regression and Panel Regression"
      ],
      "metadata": {
        "id": "P6UmEHDIa6tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install famafrench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wszAFPbkb5vm",
        "outputId": "a08814a7-dd53-4336-b457-660dcd0a9e1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: famafrench in /usr/local/lib/python3.11/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython>=7.12.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (7.34.0)\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.11/dist-packages (from famafrench) (2.0.2)\n",
            "Requirement already satisfied: numpydoc>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from famafrench) (1.8.0)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (0.60.0)\n",
            "Requirement already satisfied: methodtools>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (0.4.7)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from famafrench) (2.2.2)\n",
            "Requirement already satisfied: pandas-datareader>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (0.10.0)\n",
            "Requirement already satisfied: pandas-market-calendars>=1.1 in /usr/local/lib/python3.11/dist-packages (from famafrench) (5.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from famafrench) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (1.1.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.13 in /usr/local/lib/python3.11/dist-packages (from famafrench) (2.0.40)\n",
            "Requirement already satisfied: sphinx>=2.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (8.2.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from famafrench) (3.0.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from famafrench) (4.67.1)\n",
            "Requirement already satisfied: wrds>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from famafrench) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython>=7.12.0->famafrench) (4.9.0)\n",
            "Requirement already satisfied: wirerope>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from methodtools>=0.1.0->famafrench) (1.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.48.0->famafrench) (0.43.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from numpydoc>=0.9.2->famafrench) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->famafrench) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->famafrench) (2025.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from pandas-datareader>=0.7.0->famafrench) (5.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pandas-datareader>=0.7.0->famafrench) (2.32.3)\n",
            "Requirement already satisfied: exchange-calendars>=3.3 in /usr/local/lib/python3.11/dist-packages (from pandas-market-calendars>=1.1->famafrench) (4.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->famafrench) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (3.1.6)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (3.1.0)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=2.0->famafrench) (24.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.3.13->famafrench) (3.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.3.13->famafrench) (4.13.2)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.11/dist-packages (from wrds>=3.0.8->famafrench) (2.9.10)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas-market-calendars>=1.1->famafrench) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas-market-calendars>=1.1->famafrench) (0.12.1)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas-market-calendars>=1.1->famafrench) (0.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython>=7.12.0->famafrench) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=2.0->famafrench) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython>=7.12.0->famafrench) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython>=7.12.0->famafrench) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.7.0->famafrench) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.7.0->famafrench) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.7.0->famafrench) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.7.0->famafrench) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install yfinance statsmodels pandas numpy linearmodels pandas-datareader requests beautifulsoup4 lxml\n",
        "\n",
        "# --- Core Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from linearmodels.panel import PanelOLS, RandomEffects\n",
        "from linearmodels.panel import compare as model_compare\n",
        "from linearmodels.panel.results import PanelEffectsResults, RandomEffectsResults\n",
        "import pandas_datareader.data as web # For Fama-French data\n",
        "import requests                          # For downloading FF files (fallback, keep for now)\n",
        "from io import BytesIO                   # *** Use BytesIO instead of StringIO ***\n",
        "from zipfile import ZipFile              # For handling zipped FF files (fallback, keep for now)\n",
        "import warnings\n",
        "import sys\n",
        "import re\n",
        "import time\n",
        "import traceback # For detailed error logging if needed\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "# --- MICE Imputation Libraries (Kept) ---\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import BayesianRidge # Needed for IterativeImputer estimator\n",
        "\n",
        "# --- Removed Plotting Libraries ---\n",
        "\n",
        "# --- Settings and Configuration ---\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "from statsmodels.tools.sm_exceptions import (ValueWarning, ConvergenceWarning,\n",
        "                                             HessianInversionWarning, PerfectSeparationWarning,\n",
        "                                             CollinearityWarning, PerfectSeparationError)\n",
        "warnings.simplefilter('ignore', ValueWarning)\n",
        "warnings.simplefilter('ignore', ConvergenceWarning)\n",
        "warnings.simplefilter('ignore', HessianInversionWarning)\n",
        "warnings.simplefilter('ignore', PerfectSeparationWarning)\n",
        "warnings.simplefilter('ignore', CollinearityWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\"Variables are collinear\")\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"divide by zero encountered in scalar divide\")\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in scalar divide\")\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in divide\")\n",
        "from linearmodels.panel.utility import AbsorbingEffectWarning\n",
        "warnings.filterwarnings(\"ignore\", category=AbsorbingEffectWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
        "\n",
        "pd.set_option('display.width', 140)\n",
        "pd.set_option('display.max_columns', 18)\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "\n",
        "# --- Define Tickers for Global Transportation Firms ---\n",
        "TICKERS_TRANSPORT = [\n",
        "    'UPS', 'FDX', 'XPO', 'JYD',\n",
        "    #'DPSGY', # Often fails download\n",
        "    'AMKBY',\n",
        "    'CNI', 'CP', 'UNP', 'CSX',\n",
        "    'ODFL', 'JBHT',\n",
        "    'ZIM',\n",
        "]\n",
        "print(f\"Attempting analysis for tickers: {TICKERS_TRANSPORT}\")\n",
        "\n",
        "\n",
        "TICKER_NAMES = { # Optional mapping\n",
        "    'UPS': 'United Parcel Service', 'FDX': 'FedEx', 'XPO': 'XPO Inc.', 'JYD': 'Jayud Global Logistics',\n",
        "    #'DPSGY': 'Deutsche Post DHL',\n",
        "    'AMKBY': 'A.P. Møller - Mærsk',\n",
        "    'CNI': 'Canadian National Railway', 'CP': 'Canadian Pacific Kansas City', 'UNP': 'Union Pacific', 'CSX': 'CSX Corp.',\n",
        "    'ODFL': 'Old Dominion Freight Line', 'JBHT': 'J.B. Hunt Transport',\n",
        "    'ZIM': 'ZIM Integrated Shipping',\n",
        "}\n",
        "\n",
        "# --- Define ESG Risk Categories (Time-Invariant) based on user info ---\n",
        "esg_risk_categories = {\n",
        "    # Low Risk\n",
        "    #'DPSGY': 'Low',\n",
        "    'AMKBY': 'Low', 'CNI': 'Low', 'CP': 'Low',\n",
        "    # Medium Risk\n",
        "    'UPS': 'Medium', 'FDX': 'Medium', 'UNP': 'Medium', 'CSX': 'Medium',\n",
        "    'XPO': 'Medium', 'ODFL': 'Medium', 'JBHT': 'Medium', 'ZIM': 'Medium',\n",
        "    # High Risk\n",
        "    'JYD': 'High',\n",
        "}\n",
        "\n",
        "# --- Define Date Range ---\n",
        "START_DATE_PRICES = \"2014-01-01\" # Start earlier for prices/lags\n",
        "END_DATE_PRICES = \"2024-12-31\"\n",
        "START_DATE_ANALYSIS = \"2015-01-01\" # Analysis start date\n",
        "END_DATE_ANALYSIS = \"2023-12-31\" # Analysis end date\n",
        "\n",
        "# --- File Paths ---\n",
        "ESG_DATA_PATH = \"/content/historic_esg_scores_global_transportation.csv\" # *** USE THE CORRECT FILENAME ***\n",
        "\n",
        "# --- Parameters ---\n",
        "ESG_LAG_MONTHS = 1\n",
        "VIF_THRESHOLD = 10\n",
        "IMPUTE_DATA = True\n",
        "RUN_WITHOUT_IMPUTATION_SENSITIVITY = True\n",
        "\n",
        "# --- Version Control & Script Info ---\n",
        "SCRIPT_VERSION = \"Panel Only v14.1 - Transportation & FF DataReader\" # Updated version\n",
        "print(f\"--- Global Transportation ESG Impact Analysis Script Started ({SCRIPT_VERSION}) ---\")\n",
        "# print(f\"Tickers: {TICKERS_TRANSPORT}\") # Already printed above\n",
        "print(f\"Analysis Period: {START_DATE_ANALYSIS} to {END_DATE_ANALYSIS}\")\n",
        "print(f\"ESG Lag: {ESG_LAG_MONTHS} months\")\n",
        "print(f\"Imputation Enabled (Main Run - MICE): {IMPUTE_DATA}\")\n",
        "print(f\"Run Sensitivity without Imputation: {RUN_WITHOUT_IMPUTATION_SENSITIVITY}\")\n",
        "print(f\"Factors Path: Data fetched from K. French Library\") # Modified print\n",
        "print(f\"ESG Data Path: {ESG_DATA_PATH} (Source/Quality Not Verified by Script)\")\n",
        "\n",
        "\n",
        "# --- Advanced Imputation Function ---\n",
        "def advanced_imputation(df_input):\n",
        "    \"\"\"\n",
        "    Performs Iterative Imputation (MICE-like) on numeric columns of a DataFrame.\n",
        "    Uses BayesianRidge as the estimator by default. Handles all-NaN columns.\n",
        "    \"\"\"\n",
        "    df = df_input.copy()\n",
        "    original_index = df.index; original_cols = df.columns\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    non_numeric_cols = df.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "    if not numeric_cols: print(\"  -> Imputation: No numeric columns found.\"); return df_input\n",
        "    df_numeric = df[numeric_cols].copy(); df_non_numeric = df[non_numeric_cols].copy()\n",
        "    if df_numeric.isnull().sum().sum() == 0: print(\"  -> Imputation: No missing values detected.\"); return df_input\n",
        "\n",
        "    print(f\"  -> Imputation: Attempting Iterative Imputation (MICE) for {len(numeric_cols)} numeric columns.\")\n",
        "    n_features = len(numeric_cols); n_neighbors = min(5, n_features - 1) if n_features > 1 else 1\n",
        "    all_nan_cols = df_numeric.columns[df_numeric.isnull().all()].tolist()\n",
        "    if all_nan_cols:\n",
        "        print(f\"    -> Warning: All-NaN columns cannot be imputed: {all_nan_cols}\")\n",
        "        df_numeric_imputable = df_numeric.drop(columns=all_nan_cols); numeric_cols_imputable = df_numeric_imputable.columns.tolist()\n",
        "        if not numeric_cols_imputable: print(\"    -> Error: No imputable numeric columns remain.\"); return df_input\n",
        "        n_features = len(numeric_cols_imputable); n_neighbors = min(5, n_features - 1) if n_features > 1 else 1\n",
        "    else: df_numeric_imputable = df_numeric; numeric_cols_imputable = numeric_cols\n",
        "    if df_numeric_imputable.empty:\n",
        "         print(\"    -> Error: No numeric columns available for imputation.\")\n",
        "         if all_nan_cols: df_all_nan = df_numeric[all_nan_cols]; df_out = pd.concat([df_all_nan, df_non_numeric], axis=1); return df_out[original_cols]\n",
        "         else: return df_input\n",
        "\n",
        "    imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=42, tol=1e-3, n_nearest_features=n_neighbors, verbose=0, imputation_order='ascending')\n",
        "    try:\n",
        "        imputed_values = imputer.fit_transform(df_numeric_imputable)\n",
        "        df_imputed_numeric = pd.DataFrame(imputed_values, columns=numeric_cols_imputable, index=df_numeric_imputable.index)\n",
        "        if all_nan_cols:\n",
        "             for col in all_nan_cols: df_imputed_numeric[col] = np.nan\n",
        "        df_out = pd.concat([df_imputed_numeric, df_non_numeric], axis=1); df_out = df_out[original_cols]\n",
        "        for col in non_numeric_cols:\n",
        "             if col in df_out.columns:\n",
        "                 try: df_out[col] = df_out[col].astype(df_input[col].dtype)\n",
        "                 except Exception as type_err: print(f\"    -> Warning: Restore dtype failed '{col}': {type_err}\")\n",
        "        print(\"  -> Imputation: MICE imputation completed.\")\n",
        "        remaining_nan_count = df_out[numeric_cols].isnull().sum().sum()\n",
        "        if remaining_nan_count > 0: print(f\"  -> !!! WARNING: {remaining_nan_count} NaNs remain post-imputation. !!!\")\n",
        "        return df_out\n",
        "    except ValueError as ve: print(f\"  -> Imputation ERROR (ValueError): {ve}. Check sparse data.\"); return df_input\n",
        "    except Exception as e: print(f\"  -> Imputation ERROR (General): {e}.\"); traceback.print_exc(limit=2); return df_input\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 1: Download Stock Returns ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- 1. Downloading and Preparing Stock Returns ---\")\n",
        "stock_monthly_returns = pd.DataFrame(); tickers_available_yf = []\n",
        "try:\n",
        "    tickers_to_download = TICKERS_TRANSPORT # Use the correct list\n",
        "    all_stock_data = yf.download( tickers_to_download, start=START_DATE_PRICES, end=END_DATE_PRICES, progress=False, auto_adjust=False, actions=False, ignore_tz=True, group_by='ticker')\n",
        "    if all_stock_data.empty: raise ValueError(\"No stock price data downloaded.\")\n",
        "    price_data_list = []; available_tickers_in_download = []\n",
        "    if len(tickers_to_download) == 1: # Handle single ticker case\n",
        "        ticker = tickers_to_download[0]\n",
        "        if not all_stock_data.empty:\n",
        "            df_ticker = all_stock_data[['Adj Close']].copy()\n",
        "            if df_ticker.empty or df_ticker['Adj Close'].isnull().all(): df_ticker = all_stock_data[['Close']].copy();\n",
        "            if not (df_ticker.empty or df_ticker['Close'].isnull().all()): print(f\"  -> Warning: Using 'Close' for {ticker}.\")\n",
        "            else: print(f\"  -> Warning: No valid price for {ticker}. Skipping.\")\n",
        "            if not df_ticker.empty and not df_ticker.isnull().all().all(): df_ticker.columns = [ticker]; price_data_list.append(df_ticker); available_tickers_in_download.append(ticker)\n",
        "    else: # Handle multiple tickers\n",
        "        if isinstance(all_stock_data.columns, pd.MultiIndex):\n",
        "             valid_tickers = all_stock_data.columns.get_level_values(0).unique().tolist()\n",
        "             for ticker in tickers_to_download:\n",
        "                  if ticker in valid_tickers:\n",
        "                    try:\n",
        "                        df_ticker = all_stock_data[ticker][['Adj Close']].copy()\n",
        "                        if df_ticker.empty or df_ticker['Adj Close'].isnull().all():\n",
        "                            df_ticker = all_stock_data[ticker][['Close']].copy()\n",
        "                            if not (df_ticker.empty or df_ticker['Close'].isnull().all()): print(f\"  -> Warning: Using 'Close' for {ticker}.\")\n",
        "                            else: print(f\"  -> Warning: No valid price for {ticker}. Skipping.\"); continue\n",
        "                        if not df_ticker.empty and not df_ticker.isnull().all().all(): df_ticker.columns = [ticker]; price_data_list.append(df_ticker); available_tickers_in_download.append(ticker)\n",
        "                    except KeyError: print(f\"  -> Warning: Data for {ticker} not in MultiIndex.\")\n",
        "                  else: print(f\"  -> Warning: Ticker {ticker} requested but not in yfinance result for this run.\") # Modified message\n",
        "        else: raise TypeError(f\"Unexpected yfinance structure: {type(all_stock_data)}\") # Should be MultiIndex for multiple tickers\n",
        "\n",
        "    if not price_data_list: raise ValueError(\"No valid price data collected.\")\n",
        "    price_data = pd.concat(price_data_list, axis=1); price_data = price_data.ffill().bfill().dropna(axis=1, how='all')\n",
        "    if price_data.empty: raise ValueError(\"Price data empty after cleaning.\")\n",
        "    tickers_available_yf = sorted(list(price_data.columns)); print(f\"  -> Stock price data processed for {len(tickers_available_yf)} tickers: {tickers_available_yf}\")\n",
        "    price_data.index = pd.to_datetime(price_data.index); monthly_prices = price_data.resample('ME').last()\n",
        "    stock_monthly_returns = monthly_prices.pct_change()\n",
        "    buffer_start_date = (pd.to_datetime(START_DATE_ANALYSIS) - pd.DateOffset(months=ESG_LAG_MONTHS + 2))\n",
        "    stock_monthly_returns = stock_monthly_returns.loc[buffer_start_date:END_DATE_PRICES] # Filter includes buffer\n",
        "    if stock_monthly_returns.empty or stock_monthly_returns.isnull().all().all(): raise ValueError(\"Monthly returns empty/all NaN after date filtering.\")\n",
        "    print(f\"  -> Stock monthly returns prepared: {stock_monthly_returns.index.min().date()} to {stock_monthly_returns.index.max().date()}\")\n",
        "except Exception as e: print(f\" FATAL ERROR processing stock returns: {e}\"); traceback.print_exc(); sys.exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 2: Load and Prepare Fama-French Factors ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- 2. Loading and Preparing Fama-French Factors ---\")\n",
        "ff_factors_monthly = pd.DataFrame(); rf_col = None; available_factors_list = []\n",
        "\n",
        "try:\n",
        "    print(f\"  -> Downloading Fama-French factors using pandas-datareader...\")\n",
        "    ff_start = START_DATE_PRICES\n",
        "    ff_end = END_DATE_PRICES\n",
        "\n",
        "    try:\n",
        "        # Fetch FF5 factors (monthly is index 0)\n",
        "        ff_data_5f = web.DataReader('Developed_5_Factors', 'famafrench', start=ff_start, end=ff_end)\n",
        "        ff_monthly_5f = ff_data_5f[0].copy()\n",
        "\n",
        "        # Fetch Momentum factor (monthly is index 0)\n",
        "        ff_mom_data = web.DataReader('Developed_Mom_Factor', 'famafrench', start=ff_start, end=ff_end)\n",
        "        ff_monthly_mom = ff_mom_data[0].copy()\n",
        "\n",
        "        # Merge\n",
        "        ff_factors_raw = pd.merge(ff_monthly_5f, ff_monthly_mom, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "        # Rename columns\n",
        "        ff_factors_raw = ff_factors_raw.rename(columns={\n",
        "            'Mkt-RF': 'mkt_rf', 'SMB': 'smb', 'HML': 'hml',\n",
        "            'RMW': 'rmw', 'CMA': 'cma', 'RF': 'rf', 'Mom': 'mom'\n",
        "        })\n",
        "\n",
        "        # Data from pandas-datareader is already in decimals\n",
        "        print(\"  -> Factors downloaded and merged successfully.\")\n",
        "        print(f\"  -> Raw factors shape: {ff_factors_raw.shape}\")\n",
        "\n",
        "    except Exception as ff_err:\n",
        "        print(f\"    -> ERROR downloading/processing Fama-French factors via pandas-datareader: {ff_err}\")\n",
        "        print(\"    -> Check dataset names ('Developed_5_Factors', 'Developed_Mom_Factor') and internet connection.\")\n",
        "        traceback.print_exc(limit=1)\n",
        "        raise ValueError(\"Failed to obtain Fama-French factors.\") from ff_err\n",
        "\n",
        "    # Convert PeriodIndex to DatetimeIndex and set to month end\n",
        "    ff_factors_raw.index = ff_factors_raw.index.to_timestamp() + pd.offsets.MonthEnd(0)\n",
        "\n",
        "    # Filter by date range needed for analysis + buffer\n",
        "    buffer_start_date = (pd.to_datetime(START_DATE_ANALYSIS) - pd.DateOffset(months=ESG_LAG_MONTHS + 2))\n",
        "    ff_factors_monthly_filtered = ff_factors_raw.loc[buffer_start_date:END_DATE_PRICES].copy()\n",
        "\n",
        "    if ff_factors_monthly_filtered.empty:\n",
        "        raise ValueError(f\"No factor data found within the required date range ({buffer_start_date.date()} to {END_DATE_PRICES}).\")\n",
        "\n",
        "    # --- Imputation for Factors ---\n",
        "    if IMPUTE_DATA and ff_factors_monthly_filtered.isnull().any().any():\n",
        "        print(\"  -> Imputing missing values in factors data (if any)...\")\n",
        "        factor_numeric_cols = ff_factors_monthly_filtered.select_dtypes(include=np.number).columns\n",
        "        if not factor_numeric_cols.empty:\n",
        "             ff_factors_monthly = advanced_imputation(ff_factors_monthly_filtered)\n",
        "             if ff_factors_monthly is ff_factors_monthly_filtered: print(\"    -> Warning: Factor imputation skipped or failed.\"); ff_factors_monthly = ff_factors_monthly_filtered.copy()\n",
        "             elif ff_factors_monthly[factor_numeric_cols].isnull().any().any(): print(\"    -> Warning: NaNs may remain post-imputation.\")\n",
        "        else: print(\"    -> No numeric factors found for imputation.\"); ff_factors_monthly = ff_factors_monthly_filtered.copy()\n",
        "    else:\n",
        "        ff_factors_monthly = ff_factors_monthly_filtered.copy()\n",
        "        if not IMPUTE_DATA: print(\"  -> Imputation disabled for factors.\")\n",
        "        elif not ff_factors_monthly_filtered.isnull().any().any(): print(\"  -> No missing values detected in fetched factors.\")\n",
        "\n",
        "    # --- Identify Risk-Free Rate and Available Factors ---\n",
        "    rf_col_options = ['rf', 'risk_free_rate']\n",
        "    rf_col = next((col for col in rf_col_options if col in ff_factors_monthly.columns), None)\n",
        "    if rf_col: print(f\"  -> Using '{rf_col}' as RF.\");\n",
        "    if rf_col is None: raise ValueError(f\"Critical Error: RF column ({rf_col_options}) not found in downloaded factors.\")\n",
        "    elif ff_factors_monthly[rf_col].isnull().any(): print(f\"  -> !!! WARNING: RF column ('{rf_col}') contains NaNs after processing!!!\")\n",
        "\n",
        "    factor_cols_check_for_factors = [\"mkt_rf\", \"smb\", \"hml\", \"rmw\", \"cma\", \"mom\"]\n",
        "    available_factors_list = sorted([f for f in factor_cols_check_for_factors if f in ff_factors_monthly.columns and pd.api.types.is_numeric_dtype(ff_factors_monthly[f])])\n",
        "    if not available_factors_list: print(\"  -> !!! WARNING: No standard factors found. !!!\")\n",
        "    else: print(f\"  -> Available factors identified: {available_factors_list}\")\n",
        "\n",
        "except ValueError as ve: print(f\" FATAL ERROR processing factors: {ve}\"); sys.exit()\n",
        "except Exception as e: print(f\" FATAL ERROR processing factors: {e}\"); traceback.print_exc(); sys.exit()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 3: Load and Prepare ESG Data from CSV ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- 3. Loading and Preparing ESG Data from CSV ---\")\n",
        "esg_panel_raw = pd.DataFrame()\n",
        "try:\n",
        "    try: esg_data_loaded = pd.read_csv(ESG_DATA_PATH)\n",
        "    except FileNotFoundError: raise ValueError(f\"ESG file not found: '{ESG_DATA_PATH}'.\")\n",
        "    except Exception as e: raise ValueError(f\"Could not read ESG file '{ESG_DATA_PATH}': {e}\")\n",
        "    print(f\"  -> Raw ESG data loaded. Shape: {esg_data_loaded.shape}\")\n",
        "    original_cols = list(esg_data_loaded.columns)\n",
        "    # *** ADJUST standardization based on actual CSV columns ***\n",
        "    standardized_names = {\n",
        "        'total-score': 'total_score',\n",
        "        'e-score': 'e_score',\n",
        "        's-score': 's_score',\n",
        "        'g-score': 'g_score'\n",
        "    }\n",
        "    esg_data_loaded.columns = [standardized_names.get(re.sub(r'\\s+', '_', col).replace('.', '').lower(),\n",
        "                                                    re.sub(r'\\s+', '_', col).replace('.', '').lower())\n",
        "                               for col in esg_data_loaded.columns]\n",
        "    standardized_cols = list(esg_data_loaded.columns); print(f\"  -> Standardized ESG columns: {standardized_cols}\")\n",
        "    required_esg_cols = ['date', 'ticker', 'total_score', 'e_score', 's_score', 'g_score'] # Use standardized names\n",
        "    missing_cols = [col for col in required_esg_cols if col not in esg_data_loaded.columns];\n",
        "    if missing_cols: raise ValueError(f\"ESG CSV missing required columns: {missing_cols}.\")\n",
        "    esg_data_loaded['date'] = pd.to_datetime(esg_data_loaded['date'], errors='coerce')\n",
        "    initial_rows = len(esg_data_loaded); esg_data_loaded = esg_data_loaded.dropna(subset=['date'])\n",
        "    if len(esg_data_loaded) < initial_rows: print(f\"  -> Warning: Dropped {initial_rows - len(esg_data_loaded)} rows due to invalid ESG dates.\")\n",
        "    if esg_data_loaded.empty: raise ValueError(\"ESG data empty after removing invalid dates.\")\n",
        "    score_cols_std = ['total_score', 'e_score', 's_score', 'g_score']; # Use standardized names\n",
        "    print(f\"  -> Converting score columns to numeric: {score_cols_std}\")\n",
        "    non_numeric_issues = False\n",
        "    for col in score_cols_std:\n",
        "        initial_nan_count = esg_data_loaded[col].isnull().sum(); esg_data_loaded[col] = pd.to_numeric(esg_data_loaded[col], errors='coerce'); final_nan_count = esg_data_loaded[col].isnull().sum()\n",
        "        if final_nan_count > initial_nan_count: num_coerced = final_nan_count - initial_nan_count; print(f\"    -> CRITICAL WARNING: Column '{col}' had {num_coerced} non-numeric values converted to NaN.\"); non_numeric_issues = True\n",
        "    if non_numeric_issues and not IMPUTE_DATA: raise ValueError(f\"Non-numeric ESG scores found and imputation disabled. Clean source CSV.\")\n",
        "    elif non_numeric_issues: print(\"    -> Imputation will attempt to handle NaNs from non-numeric scores.\")\n",
        "    esg_data_loaded['ticker'] = esg_data_loaded['ticker'].astype(str).str.upper().str.strip()\n",
        "    stock_tickers_upper = [t.upper().strip() for t in tickers_available_yf]; esg_tickers = esg_data_loaded['ticker'].unique()\n",
        "    common_tickers = sorted(list(set(stock_tickers_upper) & set(esg_tickers)));\n",
        "    if not common_tickers: raise ValueError(\"No common tickers found between stock and ESG data.\")\n",
        "    print(f\"  -> Common tickers identified: {common_tickers} ({len(common_tickers)} firms)\")\n",
        "    esg_only = sorted(list(set(esg_tickers) - set(stock_tickers_upper))); stock_only = sorted(list(set(stock_tickers_upper) - set(esg_tickers)))\n",
        "    if esg_only: print(f\"    -> Tickers in ESG only: {esg_only}\")\n",
        "    if stock_only: print(f\"    -> Tickers in Stock only: {stock_only}\")\n",
        "    esg_data_filtered = esg_data_loaded[esg_data_loaded['ticker'].isin(common_tickers)].copy()\n",
        "    buffer_start_date = (pd.to_datetime(START_DATE_ANALYSIS) - pd.DateOffset(months=ESG_LAG_MONTHS + 2))\n",
        "    esg_filter_end_date = pd.to_datetime(END_DATE_ANALYSIS) + pd.offsets.MonthEnd(0)\n",
        "    esg_data_filtered = esg_data_filtered[(esg_data_filtered['date'] >= buffer_start_date) & (esg_data_filtered['date'] <= esg_filter_end_date)]\n",
        "    if esg_data_filtered.empty: raise ValueError(\"No ESG data remains after filtering.\")\n",
        "    esg_data_filtered['date'] = esg_data_filtered['date'] + pd.offsets.MonthEnd(0); esg_data_filtered = esg_data_filtered.sort_values(by=['ticker', 'date']).drop_duplicates(subset=['ticker', 'date'], keep='last')\n",
        "    panel_start_date = esg_data_filtered['date'].min(); panel_end_date = esg_data_filtered['date'].max(); print(f\"  -> Creating ESG panel from {panel_start_date.date()} to {panel_end_date.date()}\")\n",
        "    full_date_range = pd.date_range(start=panel_start_date, end=panel_end_date, freq='ME'); multi_index = pd.MultiIndex.from_product([common_tickers, full_date_range], names=['Ticker', 'Date'])\n",
        "    esg_panel_raw = esg_data_filtered.set_index(['ticker', 'date'])[score_cols_std].reindex(multi_index); print(f\"  -> Forward-filling ESG scores...\")\n",
        "    esg_panel_raw[score_cols_std] = esg_panel_raw.groupby(level='Ticker')[score_cols_std].ffill()\n",
        "    if esg_panel_raw[score_cols_std].isnull().values.any(): nan_counts = esg_panel_raw[score_cols_std].isnull().sum(); print(f\"  -> !!! WARNING: NaNs remain after ffill. Imputation will attempt. Counts:\\n{nan_counts[nan_counts > 0]}\")\n",
        "    else: print(\"  -> No NaNs detected post-ffill.\")\n",
        "    esg_panel_raw = esg_panel_raw.reset_index(); print(f\"  -> ESG panel structure created. Shape: {esg_panel_raw.shape}\")\n",
        "except Exception as e: print(f\" FATAL ERROR processing ESG data: {e}\"); traceback.print_exc(); sys.exit()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 5: Check for Multicollinearity (VIF) ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- 5. Checking for Multicollinearity (VIF) ---\")\n",
        "vif_results_total = None; vif_results_components = None\n",
        "def calculate_vif(data, predictors, model_name=\"VIF Check\"):\n",
        "    print(f\"\\n  Calculating VIF for: {model_name}\")\n",
        "    if not predictors: print(\"    -> No predictors.\"); return None, []\n",
        "    predictors_in_data = [p for p in predictors if p in data.columns]; missing = [p for p in predictors if p not in data.columns]\n",
        "    if missing: print(f\"    -> Warning: Predictors missing for VIF: {missing}\")\n",
        "    if not predictors_in_data: print(\"    -> No valid predictors.\"); return None, []\n",
        "    X = data[predictors_in_data].copy(); initial_rows = len(X); X = X.dropna(); dropped_rows = initial_rows - len(X)\n",
        "    if dropped_rows > 0: print(f\"    -> Dropped {dropped_rows} rows with NaNs for VIF.\")\n",
        "    if X.empty or len(X) < 2 or X.shape[1] < 1: print(f\"    -> Not enough data for VIF.\"); return None, predictors_in_data\n",
        "    constant_cols = X.columns[X.nunique() <= 1].tolist()\n",
        "    if constant_cols: print(f\"    -> Warning: Constant columns removed for VIF: {constant_cols}\"); X = X.drop(columns=constant_cols); predictors_in_data = X.columns.tolist();\n",
        "    if X.empty or X.shape[1] < 1: print(f\"    -> No variables left after removing constant cols.\"); return None, predictors_in_data\n",
        "    try: X_vif = sm.add_constant(X, prepend=True, has_constant='skip')\n",
        "    except Exception as e: print(f\"    -> Error adding constant: {e}.\"); return None, predictors_in_data\n",
        "    if not np.all(np.isfinite(X_vif.values)): print(\"    -> Warning: Non-finite values detected. Attempting removal...\"); X_vif = X_vif.replace([np.inf, -np.inf], np.nan).dropna();\n",
        "    if X_vif.empty: print(\"    -> Error: Data empty after removing non-finite.\"); return None, predictors_in_data\n",
        "    try:\n",
        "        vif_data = pd.DataFrame(); vif_data[\"Variable\"] = [col for col in X_vif.columns if col.lower() != 'const']\n",
        "        vif_values = [variance_inflation_factor(X_vif.values.astype(float), i) for i, col in enumerate(X_vif.columns) if col.lower() != 'const']\n",
        "        vif_data[\"VIF\"] = vif_values; print(vif_data.sort_values('VIF', ascending=False).to_string(index=False))\n",
        "        high_vif_vars = vif_data[vif_data[\"VIF\"] > VIF_THRESHOLD][\"Variable\"].tolist()\n",
        "        if high_vif_vars: print(f\"    -> !!! WARNING: High VIF (> {VIF_THRESHOLD}): {high_vif_vars}. !!!\")\n",
        "        else: print(f\"    -> VIF check passed (threshold={VIF_THRESHOLD}).\")\n",
        "        return vif_data, predictors_in_data\n",
        "    except (np.linalg.LinAlgError, ValueError) as vif_calc_err: print(f\"    -> VIF calc failed: {vif_calc_err} (Perfect multicollinearity likely).\"); return None, predictors_in_data\n",
        "    except Exception as e: print(f\"    -> VIF error: {e}\"); traceback.print_exc(); return None, predictors_in_data\n",
        "\n",
        "# *** Use standardized variable name from Step 4 ***\n",
        "primary_esg_var = f'total_score_lag{ESG_LAG_MONTHS}' if f'total_score_lag{ESG_LAG_MONTHS}' in final_panel_data.columns else None\n",
        "component_esg_vars = [col for col in [f'e_score_lag{ESG_LAG_MONTHS}', f's_score_lag{ESG_LAG_MONTHS}', f'g_score_lag{ESG_LAG_MONTHS}'] if col in final_panel_data.columns]\n",
        "if primary_esg_var:\n",
        "    predictors_total_vif = available_factors + [primary_esg_var]; predictors_total_vif = [p for p in predictors_total_vif if p in final_panel_data.columns]\n",
        "    if predictors_total_vif: vif_results_total, _ = calculate_vif(final_panel_data.reset_index(), predictors_total_vif, \"Factors + Total ESG\")\n",
        "    else: print(\" -> Skipping VIF (Total ESG): No valid predictors.\")\n",
        "else: print(\"  -> Skipping VIF (Total ESG): Primary ESG var missing.\")\n",
        "if component_esg_vars:\n",
        "    predictors_components_vif = available_factors + component_esg_vars; predictors_components_vif = [p for p in predictors_components_vif if p in final_panel_data.columns]\n",
        "    if predictors_components_vif: vif_results_components, _ = calculate_vif(final_panel_data.reset_index(), predictors_components_vif, \"Factors + ESG Components\")\n",
        "    else: print(\" -> Skipping VIF (Components): No valid predictors.\")\n",
        "else: print(\"  -> Skipping VIF (Components): ESG component vars missing.\")\n",
        "if primary_esg_var: print(f\"\\n  -> Primary ESG var for models: '{primary_esg_var}'\")\n",
        "if component_esg_vars: print(f\"  -> Component ESG vars: {component_esg_vars}\")\n",
        "if not primary_esg_var and not component_esg_vars: print(\"\\n!!! WARNING: No lagged ESG vars available. !!!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 6: Panel Regression Analysis ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- 6. Panel Regression Analysis (Main Run - Imputed Data if Enabled) ---\")\n",
        "regression_results = {}; model_summaries = {}; sensitivity_regression_results = {}; model_formulas_used = {}\n",
        "sensitivity_summaries = {}; sensitivity_formulas_used = {} # Separate dicts for sensitivity\n",
        "\n",
        "formula_pooled_interaction = None; formula_fe_re_simple = None\n",
        "if primary_esg_var and available_factors:\n",
        "    base_factors_str = ' + '.join(available_factors); esg_term = primary_esg_var\n",
        "    # *** Use standardized variable name ***\n",
        "    formula_fe_re_simple = f\"ExcessReturn ~ 1 + {base_factors_str} + {esg_term}\"; print(f\"\\n  -> Formula for FE & RE models: {formula_fe_re_simple}\")\n",
        "    if lagged_category_col and lagged_category_col in final_panel_data.columns and final_panel_data[lagged_category_col].nunique() > 1:\n",
        "        preferred_reference_category = 'Medium'; print(f\"  -> Attempting to set '{preferred_reference_category}' as reference category for Pooled OLS.\")\n",
        "        available_cats = [c for c in final_panel_data[lagged_category_col].unique() if isinstance(c, str)]; final_reference_category = None\n",
        "        if preferred_reference_category in available_cats: final_reference_category = preferred_reference_category; print(f\"     -> Found exact match: Using '{final_reference_category}'.\")\n",
        "        else:\n",
        "            ref_cat_lower = preferred_reference_category.lower(); matching_cats = [c for c in available_cats if c.lower() == ref_cat_lower]\n",
        "            if matching_cats: final_reference_category = matching_cats[0]; print(f\"     -> Found case-insensitive match: Using '{final_reference_category}'.\")\n",
        "            elif available_cats:\n",
        "                 most_frequent_cat = final_panel_data[lagged_category_col].mode()\n",
        "                 if not most_frequent_cat.empty: final_reference_category = most_frequent_cat[0]; print(f\"     -> '{preferred_reference_category}' not found. Using most frequent category '{final_reference_category}' as fallback reference.\")\n",
        "                 else: print(f\"     -> Warning: Could not determine most frequent category. Cannot create Pooled OLS interaction formula.\")\n",
        "            else: print(f\"     -> Warning: No valid string categories found. Cannot create Pooled OLS interaction formula.\")\n",
        "        if final_reference_category: interaction_term = f\"{esg_term} * C({lagged_category_col}, Treatment(reference='{final_reference_category}'))\"; formula_pooled_interaction = f\"ExcessReturn ~ 1 + {base_factors_str} + {interaction_term}\"; print(f\"  -> Formula for Pooled OLS (Interaction): {formula_pooled_interaction}\")\n",
        "        else: print(f\"  -> Warn: Could not determine reference category. Using simple formula for Pooled OLS.\"); formula_pooled_interaction = formula_fe_re_simple\n",
        "    else:\n",
        "        if not lagged_category_col or lagged_category_col not in final_panel_data.columns: reason = \"missing\"\n",
        "        else: reason = \"has <= 1 unique value\"\n",
        "        print(f\"  -> Warn: Category column ('{lagged_category_col}') {reason}. Using simple formula for Pooled OLS.\"); formula_pooled_interaction = formula_fe_re_simple\n",
        "else: missing_info = [];\n",
        "if not primary_esg_var: missing_info.append(\"primary ESG variable\")\n",
        "if not available_factors: missing_info.append(\"factor variables\"); print(f\"\\n!!! CRITICAL WARNING: Cannot construct formulas (missing {', '.join(missing_info)}). Regression cannot proceed. !!!\")\n",
        "\n",
        "def run_panel_model(formula, model_type, model_key, data,\n",
        "                    cov_config={'cov_type':'clustered', 'cluster_entity':True, 'cluster_time': False},\n",
        "                    results_dict=None, summary_dict=None, formula_dict=None):\n",
        "    \"\"\"Fits panel model, handles errors, stores results/summaries.\"\"\"\n",
        "    print(f\"\\n  --- Fitting {model_key} ({model_type}) ---\")\n",
        "    if results_dict is None: results_dict = {}\n",
        "    if summary_dict is None: summary_dict = {}\n",
        "    if formula_dict is None: formula_dict = {}\n",
        "    results = None; error_msg = None; formula_status = \"Attempted\"\n",
        "    if not formula: error_msg = \"Skipped: No formula.\"; formula_status = \"Skipped - No Formula\"\n",
        "    elif data is None or data.empty: error_msg = \"Skipped: Empty data.\"; formula_status = \"Skipped - Empty Data\"\n",
        "    if error_msg: print(f\"    -> {error_msg}\"); summary_dict[model_key] = error_msg; results_dict[model_key] = None; formula_dict[model_key] = formula_status; return\n",
        "    try:\n",
        "        print(f\"    Using Formula: {formula}\")\n",
        "        dep, exog_formula = formula.split('~', 1); dep = dep.strip(); exog_formula = exog_formula.strip()\n",
        "        final_cov_config = cov_config.copy(); model = None; summary_obj = None\n",
        "        if model_type == 'Pooled':\n",
        "            pooled_cov_config = {'cov_type': 'robust'}; print(\"     (Note: Using robust covariance for Pooled OLS)\")\n",
        "            model = PanelOLS.from_formula(formula, data=data); final_cov_config = pooled_cov_config; formula_status = \"Pooled Spec (Robust SE)\"\n",
        "        elif model_type == 'RE':\n",
        "            model = RandomEffects.from_formula(formula, data=data)\n",
        "            if 'cluster' not in cov_config.get('cov_type','robust').lower(): final_cov_config = {'cov_type': 'robust'}\n",
        "            else: print(\"     (Note: Applying requested clustering to RE model)\")\n",
        "            formula_status = \"RE Spec\"\n",
        "        elif model_type == 'FE_Entity':\n",
        "            model = PanelOLS.from_formula(f\"{dep} ~ {exog_formula} + EntityEffects\", data=data, drop_absorbed=True); final_cov_config['cluster_time'] = False; formula_status = \"FE Entity Spec\"\n",
        "        elif model_type == 'FE_TwoWay':\n",
        "            model = PanelOLS.from_formula(f\"{dep} ~ {exog_formula} + EntityEffects + TimeEffects\", data=data, drop_absorbed=True); final_cov_config['cluster_time'] = True; formula_status = \"FE TwoWay Spec\"\n",
        "        else: raise ValueError(f\"Invalid model_type: {model_type}\")\n",
        "        results = model.fit(**final_cov_config); print(f\"    -> Fit OK.\")\n",
        "        try:\n",
        "             summary_obj = results.summary; print(f\"    -> Summary generation OK.\")\n",
        "             summary_dict[model_key] = summary_obj\n",
        "             if model_type.startswith('FE'):\n",
        "                 summary_str = str(summary_obj); # Define summary_str here\n",
        "                 if 'Absorbed' in summary_str or 'dropped' in summary_str.lower(): print(\"    -> Warning: Summary indicates potential variable absorption/dropping.\")\n",
        "        except (np.linalg.LinAlgError, ValueError) as summary_err: error_msg = f\"Error: Summary failed - {type(summary_err).__name__}: {summary_err} (Singular matrix likely).\"; print(f\"    -> {error_msg}\"); summary_dict[model_key] = error_msg; results_dict[model_key] = results; formula_dict[model_key] = formula_status + \" (Summary Failed)\"; return\n",
        "        except Exception as gen_summary_err: error_msg = f\"Error: Unexpected summary error - {type(gen_summary_err).__name__}: {gen_summary_err}\"; print(f\"    -> {error_msg}\"); summary_dict[model_key] = error_msg; results_dict[model_key] = results; formula_dict[model_key] = formula_status + \" (Summary Failed - Unknown)\"; return\n",
        "    except (ValueError, np.linalg.LinAlgError, PerfectSeparationError, ZeroDivisionError) as fit_err: error_msg = f\"Error: Fit failed - {type(fit_err).__name__}: {fit_err}\"; print(f\"    -> {error_msg}\")\n",
        "    except Exception as e: error_msg = f\"Error: Unexpected fit error - {type(e).__name__}: {e}\"; print(f\"    -> {error_msg}\"); traceback.print_exc(limit=1)\n",
        "    if results is not None and error_msg is None: results_dict[model_key] = results; formula_dict[model_key] = formula_status + \" (Success)\"\n",
        "    elif results is not None and error_msg is not None: pass\n",
        "    else: results_dict[model_key] = None; summary_dict[model_key] = error_msg; formula_dict[model_key] = formula_status + \" (Fit Failed)\"\n",
        "\n",
        "# --- Run Main Models ---\n",
        "if formula_pooled_interaction and formula_fe_re_simple:\n",
        "    run_panel_model(formula_pooled_interaction, 'Pooled', 'Pooled_Interaction', final_panel_data, results_dict=regression_results, summary_dict=model_summaries, formula_dict=model_formulas_used)\n",
        "    run_panel_model(formula_fe_re_simple, 'RE', 'RE_Simple', final_panel_data, results_dict=regression_results, summary_dict=model_summaries, formula_dict=model_formulas_used)\n",
        "    run_panel_model(formula_fe_re_simple, 'FE_Entity', 'FE_Entity_Simple', final_panel_data, results_dict=regression_results, summary_dict=model_summaries, formula_dict=model_formulas_used)\n",
        "    run_panel_model(formula_fe_re_simple, 'FE_TwoWay', 'FE_TwoWay_Simple', final_panel_data, results_dict=regression_results, summary_dict=model_summaries, formula_dict=model_formulas_used)\n",
        "else: print(\"\\n!!! Skipping main panel estimations: Missing required formulas. !!!\")\n",
        "\n",
        "# --- Run Sensitivity Analysis (No Imputation) ---\n",
        "if RUN_WITHOUT_IMPUTATION_SENSITIVITY:\n",
        "    print(\"\\n--- 6b. Panel Regression Analysis (Sensitivity Run - NO IMPUTATION) ---\")\n",
        "    if panel_data_no_imputation is None or panel_data_no_imputation.empty:\n",
        "        print(\"    -> Skipping Sensitivity: Non-imputed dataset empty.\")\n",
        "        sensitivity_regression_results['Pooled_Interaction_Sens'] = None; sensitivity_summaries['Pooled_Interaction_Sens'] = \"Skipped - Empty Data\"; sensitivity_formulas_used['Pooled_Interaction_Sens'] = \"Skipped - Empty Data\"\n",
        "        sensitivity_regression_results['FE_Entity_Simple_Sens'] = None; sensitivity_summaries['FE_Entity_Simple_Sens'] = \"Skipped - Empty Data\"; sensitivity_formulas_used['FE_Entity_Simple_Sens'] = \"Skipped - Empty Data\"\n",
        "    elif formula_pooled_interaction and formula_fe_re_simple:\n",
        "        panel_data_no_imputation_indexed = None\n",
        "        if isinstance(panel_data_no_imputation.index, pd.MultiIndex): panel_data_no_imputation_indexed = panel_data_no_imputation.copy()\n",
        "        elif {'Ticker', 'Date'}.issubset(panel_data_no_imputation.columns):\n",
        "             panel_data_no_imputation_idx_temp = panel_data_no_imputation.copy(); panel_data_no_imputation_idx_temp['Date'] = pd.to_datetime(panel_data_no_imputation_idx_temp['Date'])\n",
        "             panel_data_no_imputation_indexed = panel_data_no_imputation_idx_temp.set_index(['Ticker', 'Date']).sort_index()\n",
        "        if panel_data_no_imputation_indexed is not None:\n",
        "            run_panel_model(formula_pooled_interaction, 'Pooled', 'Pooled_Interaction_Sens', panel_data_no_imputation_indexed, results_dict=sensitivity_regression_results, summary_dict=sensitivity_summaries, formula_dict=sensitivity_formulas_used)\n",
        "            run_panel_model(formula_fe_re_simple, 'FE_Entity', 'FE_Entity_Simple_Sens', panel_data_no_imputation_indexed, results_dict=sensitivity_regression_results, summary_dict=sensitivity_summaries, formula_dict=sensitivity_formulas_used)\n",
        "        else: print(\"    -> Error: Cannot set index for sensitivity data. Skipping.\"); sensitivity_summaries['Pooled_Interaction_Sens'] = \"Skipped - Index Error\"; sensitivity_summaries['FE_Entity_Simple_Sens'] = \"Skipped - Index Error\"; sensitivity_formulas_used['Pooled_Interaction_Sens'] = \"Skipped - Index Error\"; sensitivity_formulas_used['FE_Entity_Simple_Sens'] = \"Skipped - Index Error\"\n",
        "    else: print(\"    -> Skipping Sensitivity: Missing required formulas.\"); sensitivity_summaries['Pooled_Interaction_Sens'] = \"Skipped - No Formula\"; sensitivity_summaries['FE_Entity_Simple_Sens'] = \"Skipped - No Formula\"; sensitivity_formulas_used['Pooled_Interaction_Sens'] = \"Skipped - No Formula\"; sensitivity_formulas_used['FE_Entity_Simple_Sens'] = \"Skipped - No Formula\"\n",
        "else: print(\"\\n--- Sensitivity Analysis Skipped (Configured Off). ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 7: Specification Tests & Interpretation ---\n",
        "# ==============================================================================\n",
        "print(\"\\n--- 7. Specification Tests & Interpretation (using Main Run results) ---\")\n",
        "spec_test_results_list = []; preferred_model_key = None\n",
        "fe_model = regression_results.get('FE_Entity_Simple'); re_model = regression_results.get('RE_Simple')\n",
        "pooled_model = regression_results.get('Pooled_Interaction'); fe_tw_model = regression_results.get('FE_TwoWay_Simple')\n",
        "is_fe_valid = isinstance(fe_model, PanelEffectsResults); is_re_valid = isinstance(re_model, RandomEffectsResults)\n",
        "is_pooled_valid = isinstance(pooled_model, PanelEffectsResults); is_fe_tw_valid = isinstance(fe_tw_model, PanelEffectsResults)\n",
        "\n",
        "try:\n",
        "    print(\"\\n    Comparing FE (Simple) vs RE (Simple) - Hausman Test:\")\n",
        "    if is_fe_valid and is_re_valid:\n",
        "        try:\n",
        "            common_params = list(set(fe_model.params.index) & set(re_model.params.index))\n",
        "            if not common_params: print(\"      -> Skipping Hausman: No common parameters.\"); spec_test_results_list.append({'Test': 'Hausman (FE vs RE - Simple)', 'Details': 'No common parameters', 'P-value': '-', 'Conclusion': 'Cannot Run'})\n",
        "            else:\n",
        "                print(\"      -> Performing Hausman test via model comparison...\"); comparison_fe_re = model_compare({\"FE_Simple\": fe_model, \"RE_Simple\": re_model})\n",
        "                print(comparison_fe_re); hausman_pval_str = \"See Table\"; pval_num = np.nan\n",
        "                try:\n",
        "                    summary_str = str(comparison_fe_re); match = re.search(r\"Hausman\\s+([\\d\\.]+)\", summary_str);\n",
        "                    if match: pval_num = float(match.group(1)); hausman_pval_str = f\"{pval_num:.4f}\"\n",
        "                except Exception as parse_err: print(f\"       -> Warning: Could not parse Hausman p-value: {parse_err}\")\n",
        "                conclusion_hausman_test = 'Check Table';\n",
        "                if not pd.isna(pval_num): conclusion_hausman_test = 'Prefer FE if Hausman p < 0.05'\n",
        "                spec_test_results_list.append({'Test': 'Hausman (FE vs RE - Simple)', 'Details': 'Comparison table printed', 'P-value': hausman_pval_str, 'Conclusion': conclusion_hausman_test})\n",
        "        except Exception as comp_e: print(f\"      -> Error running Hausman comparison: {comp_e}\"); spec_test_results_list.append({'Test': 'Hausman (FE vs RE - Simple)', 'Details': f\"Error: {comp_e}\", 'P-value': '-', 'Conclusion': 'Error'})\n",
        "    else: details = \"RE invalid\" if is_fe_valid else \"FE invalid\" if is_re_valid else \"Both invalid\"; print(f\"\\n    Skipping Hausman test: {details}.\"); spec_test_results_list.append({'Test': 'Hausman (FE vs RE - Simple)', 'Details': details, 'P-value': '-', 'Conclusion': 'Cannot Run'})\n",
        "\n",
        "    print(\"\\n    F-test for Poolability (Entity Effects):\")\n",
        "    if is_fe_valid:\n",
        "        try:\n",
        "            if hasattr(fe_model, 'f_pooled'):\n",
        "                f_pool = fe_model.f_pooled; stat_val = f_pool.stat; pval_val = f_pool.pval; df_num = getattr(f_pool, 'df_num', '?'); df_denom = getattr(f_pool, 'df_denom', '?')\n",
        "                print(f\"      F={stat_val:.4f}, P-value={pval_val:.4f} (df_num={df_num}, df_denom={df_denom})\"); conclusion = 'Reject Pooling (Use FE)' if pval_val < 0.05 else 'Cannot Reject Pooling (Pooled OK)'\n",
        "                spec_test_results_list.append({'Test': 'F-test (Poolability - Entity)', 'Details': f'F({df_num},{df_denom})={stat_val:.4f}', 'P-value': f'{pval_val:.4f}', 'Conclusion': conclusion})\n",
        "            else: print(\"      -> Poolability F-stat (f_pooled) not available.\"); spec_test_results_list.append({'Test': 'F-test (Poolability - Entity)', 'Details': 'f_pooled unavailable', 'P-value': '-', 'Conclusion': 'Cannot Run'})\n",
        "        except Exception as ftest_e: print(f\"      -> Error accessing Poolability F-test: {ftest_e}\"); spec_test_results_list.append({'Test': 'F-test (Poolability - Entity)', 'Details': f\"Error: {ftest_e}\", 'P-value': '-', 'Conclusion': 'Error'})\n",
        "    else: print(\"      -> Skipping Poolability F-test: FE (Simple) model invalid.\"); spec_test_results_list.append({'Test': 'F-test (Poolability - Entity)', 'Details': 'FE Invalid', 'P-value': '-', 'Conclusion': 'Cannot Run'})\n",
        "\n",
        "    print(\"\\n    F-test for Time Effects:\");\n",
        "    if is_fe_tw_valid:\n",
        "         try:\n",
        "            if hasattr(fe_tw_model, 'f_test_time'):\n",
        "                f_time = fe_tw_model.f_test_time; stat_val = f_time.stat; pval_val = f_time.pval; df_num = getattr(f_time, 'df_num', '?'); df_denom = getattr(f_time, 'df_denom', '?')\n",
        "                print(f\"      F={stat_val:.4f}, P-value={pval_val:.4f} (df_num={df_num}, df_denom={df_denom})\"); conclusion = 'Time Effects Significant (Use Two-Way FE)' if pval_val < 0.05 else 'Time Effects Not Significant (Entity FE OK)'\n",
        "                spec_test_results_list.append({'Test': 'F-test (Time Effects)', 'Details': f'F({df_num},{df_denom})={stat_val:.4f}', 'P-value': f'{pval_val:.4f}', 'Conclusion': conclusion})\n",
        "            else: print(\"      -> Time Effects F-stat (f_test_time) not available.\"); spec_test_results_list.append({'Test': 'F-test (Time Effects)', 'Details': 'f_test_time unavailable', 'P-value': '-', 'Conclusion': 'Cannot Run'})\n",
        "         except Exception as ftest_e: print(f\"      -> Error accessing Time Effects F-test: {ftest_e}\"); spec_test_results_list.append({'Test': 'F-test (Time Effects)', 'Details': f\"Error: {ftest_e}\", 'P-value': '-', 'Conclusion': 'Error'})\n",
        "    else: print(\"      -> Skipping Time Effects F-test: Two-Way FE (Simple) model invalid.\"); spec_test_results_list.append({'Test': 'F-test (Time Effects)', 'Details': 'Two-Way FE Invalid', 'P-value': '-', 'Conclusion': 'Cannot Run'})\n",
        "    spec_test_df = pd.DataFrame(spec_test_results_list)\n",
        "except Exception as e: print(f\"\\nError during spec tests: {e}\"); traceback.print_exc(); spec_test_df = pd.DataFrame()\n",
        "\n",
        "print(\"\\n--- Preferred Model Selection Logic (Main Run) ---\")\n",
        "conclusion_pool = 'Cannot Run'; conclusion_time = 'Cannot Run'; conclusion_hausman = 'Cannot Run'\n",
        "if not spec_test_df.empty:\n",
        "    pool_row = spec_test_df[spec_test_df['Test'] == 'F-test (Poolability - Entity)']; conclusion_pool = pool_row['Conclusion'].iloc[0] if not pool_row.empty else 'Cannot Run'\n",
        "    time_row = spec_test_df[spec_test_df['Test'] == 'F-test (Time Effects)']; conclusion_time = time_row['Conclusion'].iloc[0] if not time_row.empty else 'Cannot Run'\n",
        "    hausman_row = spec_test_df[spec_test_df['Test'] == 'Hausman (FE vs RE - Simple)']; conclusion_hausman = hausman_row['Conclusion'].iloc[0] if not hausman_row.empty else 'Cannot Run'\n",
        "print(f\"  - Poolability Test Result: '{conclusion_pool}'\"); print(f\"  - Hausman Test (Simple Models) Result: '{conclusion_hausman}'\"); print(f\"  - Time Effects Test Result: '{conclusion_time}'\")\n",
        "\n",
        "preferred_model_key = None # Reset\n",
        "if 'Time Effects Significant' in conclusion_time and is_fe_tw_valid:\n",
        "    print(\"  - Logic: Time effects significant & Two-Way FE valid.\"); preferred_model_key = 'FE_TwoWay_Simple'; print(\"  -> Tentative Preference: FE Two-Way (Simple).\")\n",
        "elif 'Reject Pooling' in conclusion_pool and is_fe_valid:\n",
        "    print(\"  - Logic: Pooling rejected & Entity FE valid.\")\n",
        "    if 'Prefer FE' in conclusion_hausman: print(\"  - Logic: Hausman also prefers FE.\"); preferred_model_key = 'FE_Entity_Simple'; print(\"  -> Tentative Preference: FE Entity (Simple).\")\n",
        "    else: print(f\"  - Logic: Hausman ({conclusion_hausman}), but Poolability rejects Pooled. Prioritizing FE Entity.\"); preferred_model_key = 'FE_Entity_Simple'; print(\"  -> Tentative Preference: FE Entity (Simple).\")\n",
        "elif is_re_valid and 'Prefer FE' not in conclusion_hausman:\n",
        "     print(\"  - Logic: FE not selected/valid, RE valid, Hausman doesn't strongly prefer FE.\"); preferred_model_key = 'RE_Simple'; print(\"  -> Tentative Preference: RE (Simple).\")\n",
        "elif 'Cannot Reject Pooling' in conclusion_pool and is_pooled_valid:\n",
        "     print(\"  - Logic: FE/RE models not selected/valid, Pooling allowed, Pooled OLS valid.\"); preferred_model_key = 'Pooled_Interaction'; print(\"  -> Tentative Preference: Pooled OLS (Interaction).\")\n",
        "if preferred_model_key is None:\n",
        "    print(\"\\n  - No model selected by primary logic. Applying fallback...\")\n",
        "    fallback_order = ['FE_TwoWay_Simple', 'FE_Entity_Simple', 'RE_Simple', 'Pooled_Interaction']\n",
        "    for model_key_fb in fallback_order:\n",
        "        if model_key_fb in regression_results and isinstance(regression_results.get(model_key_fb), (PanelEffectsResults, RandomEffectsResults)):\n",
        "            summary_val = model_summaries.get(model_key_fb)\n",
        "            if not isinstance(summary_val, str): preferred_model_key = model_key_fb; print(f\"  -> Fallback Selection: '{preferred_model_key}'.\"); break\n",
        "            else: print(f\"      -> Skipping fallback {model_key_fb} (summary failed).\")\n",
        "if preferred_model_key and (preferred_model_key not in regression_results or not isinstance(regression_results.get(preferred_model_key), (PanelEffectsResults, RandomEffectsResults))): print(f\"  -> ERROR: Preferred model '{preferred_model_key}' not valid. Resetting.\"); preferred_model_key = None\n",
        "if preferred_model_key and preferred_model_key in model_summaries and isinstance(model_summaries[preferred_model_key], str): print(f\"  -> ERROR: Preferred model '{preferred_model_key}' failed summary. Resetting.\"); preferred_model_key = None\n",
        "if preferred_model_key is None: print(\"\\n  -> !!! CRITICAL: No valid model results available after fallback. !!!\")\n",
        "print(f\"\\n---> Final Preferred Model Selected (Main Run): {preferred_model_key if preferred_model_key else 'None (Review Logs)'} <---\")\n",
        "\n",
        "print(f\"\\n--- Interpretation (Based on '{preferred_model_key if preferred_model_key else 'Available Models'}') ---\")\n",
        "interpretation_provided = False\n",
        "def get_coeff_info(results, var_name):\n",
        "    if results and hasattr(results, 'params') and var_name in results.params.index:\n",
        "        coeff = results.params.get(var_name); pval = results.pvalues.get(var_name); stderr = results.std_errors.get(var_name)\n",
        "        sig_marker = '***' if pval < 0.001 else '**' if pval < 0.01 else '*' if pval < 0.05 else '.' if pval < 0.1 else ''\n",
        "        return f\"Coeff={coeff:.4f}, SE={stderr:.4f}, Pval={pval:.4f} {sig_marker}\"\n",
        "    return f\"Variable '{var_name}' not found or results invalid.\"\n",
        "\n",
        "if preferred_model_key and preferred_model_key in regression_results and isinstance(regression_results[preferred_model_key], (PanelEffectsResults, RandomEffectsResults)):\n",
        "    preferred_model_results = regression_results[preferred_model_key]; formula_used_key = model_formulas_used.get(preferred_model_key, \"Unknown\")\n",
        "    print(f\"    Interpreting Preferred Model: '{preferred_model_key}' (Formula Type: {formula_used_key})\")\n",
        "    if primary_esg_var:\n",
        "        print(f\"\\n    Interpretation for '{primary_esg_var}':\")\n",
        "        if preferred_model_key == 'Pooled_Interaction' and any(':' in p for p in preferred_model_results.params.index):\n",
        "             ref_cat_used = 'Unknown'; formula_string_to_parse = formula_pooled_interaction\n",
        "             if formula_string_to_parse:\n",
        "                  try: match = re.search(r\"Treatment\\(reference='([^']+)'\\)\", formula_string_to_parse); ref_cat_used = match.group(1) if match else 'Unknown'\n",
        "                  except Exception: pass\n",
        "             print(f\"      Model includes interactions (Ref Cat: '{ref_cat_used}')\"); print(f\"      - Baseline Effect ({ref_cat_used}): {get_coeff_info(preferred_model_results, primary_esg_var)}\"); print(\"      - (Interactions: See Pooled summary)\")\n",
        "        elif preferred_model_key in ['FE_Entity_Simple', 'FE_TwoWay_Simple', 'RE_Simple']:\n",
        "             effects_description = \"Unknown\"\n",
        "             if 'FE_Entity' in preferred_model_key: effects_description = \"Entity Fixed\"\n",
        "             elif 'FE_TwoWay' in preferred_model_key: effects_description = \"Entity & Time Fixed\"\n",
        "             elif 'RE' in preferred_model_key: effects_description = \"Random Entity\"\n",
        "             print(f\"      Model estimates avg effect controlling for {effects_description} effects.\"); print(f\"      - Average Effect: {get_coeff_info(preferred_model_results, primary_esg_var)}\")\n",
        "        else: print(f\"      - Unknown structure. Basic Effect: {get_coeff_info(preferred_model_results, primary_esg_var)}\")\n",
        "    else: print(\"    -> Primary ESG variable not specified/found.\")\n",
        "    print(\"\\n    Interpretation Notes:\"); print(f\"      - Results based on '{preferred_model_key}'. Check Pval.\");\n",
        "    if IMPUTE_DATA and initial_missing_stats: print(\"      - !!! CAVEAT: Uses imputed data. High initial missingness. Compare w/ Sensitivity. !!!\")\n",
        "    print(\"      - Consider economic significance.\"); interpretation_provided = True\n",
        "elif RUN_WITHOUT_IMPUTATION_SENSITIVITY:\n",
        "    print(\"\\n    -> Main run failed/not selected. Checking Sensitivity Run...\")\n",
        "    sens_key_to_interpret = None; sens_results = None; sens_pref_order = ['FE_Entity_Simple_Sens', 'Pooled_Interaction_Sens']\n",
        "    for key in sens_pref_order:\n",
        "        result_obj = sensitivity_regression_results.get(key) # Check result object\n",
        "        summary_obj_or_err = sensitivity_summaries.get(key) # Check summary object/error\n",
        "        if isinstance(result_obj, (PanelEffectsResults, RandomEffectsResults)) and not isinstance(summary_obj_or_err, str):\n",
        "            sens_key_to_interpret = key; sens_results = result_obj; break\n",
        "    if sens_key_to_interpret and sens_results:\n",
        "        print(f\"    -> Interpreting Sensitivity Model: '{sens_key_to_interpret}' (NO IMPUTATION) as fallback.\"); print(\"       !!! CAVEATS: Smaller subset of data. !!!\")\n",
        "        if primary_esg_var: print(f\"       - ESG Effect ('{primary_esg_var}'): {get_coeff_info(sens_results, primary_esg_var)}\")\n",
        "        else: print(\"       - Primary ESG variable not found.\"); interpretation_provided = True\n",
        "    else: print(\"    -> Sensitivity models also failed or were skipped.\")\n",
        "if not interpretation_provided: print(\"\\n    -> No valid model results found to provide interpretation.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# --- Step 9: Print Consolidated Results to Console ---\n",
        "# ==============================================================================\n",
        "print(\"\\n\\n==============================================================================\")\n",
        "print(f\"--- 9. Consolidated Analysis Results ({SCRIPT_VERSION}) ---\")\n",
        "print(\"==============================================================================\")\n",
        "\n",
        "print(f\"\\n--- Panel Model Summaries (Main Run - Imputed: {IMPUTE_DATA}) ---\")\n",
        "if not model_summaries: print(\"No models run/attempted.\")\n",
        "else:\n",
        "    model_order = ['Pooled_Interaction', 'RE_Simple', 'FE_Entity_Simple', 'FE_TwoWay_Simple']\n",
        "    for name in model_order:\n",
        "        if name in model_summaries:\n",
        "            result_or_error_summary = model_summaries[name]\n",
        "            formula_used_key = model_formulas_used.get(name, \"Unknown\")\n",
        "            print(f\"\\n--- Model: {name} ---\"); print(f\"    Formula Type Used: {formula_used_key}\")\n",
        "            if isinstance(result_or_error_summary, str): print(f\"    -> Model Failed/Summary Error: {result_or_error_summary}\")\n",
        "            elif hasattr(result_or_error_summary, 'tables'):\n",
        "                try:\n",
        "                    if hasattr(result_or_error_summary, 'tables') and isinstance(result_or_error_summary.tables, list):\n",
        "                         for table in result_or_error_summary.tables: print(table.as_text())\n",
        "                    else: print(str(result_or_error_summary))\n",
        "                except Exception as e: print(f\"    -> Error formatting/printing summary tables for '{name}': {e}\");\n",
        "                try: print(str(result_or_error_summary))\n",
        "                except: print(\"    -> Could not even convert summary object to string.\")\n",
        "            else: print(f\"    -> Unknown result status stored (Type: {type(result_or_error_summary)}): {result_or_error_summary}\")\n",
        "\n",
        "if RUN_WITHOUT_IMPUTATION_SENSITIVITY:\n",
        "    print(\"\\n\\n--- Panel Model Summaries (Sensitivity Run - NO IMPUTATION) ---\")\n",
        "    if not sensitivity_summaries: print(\"No sensitivity models run/results available.\")\n",
        "    else:\n",
        "        sens_model_order = ['Pooled_Interaction_Sens', 'FE_Entity_Simple_Sens']\n",
        "        for name in sens_model_order:\n",
        "             if name in sensitivity_summaries:\n",
        "                result_or_error_summary = sensitivity_summaries[name]\n",
        "                formula_used_key = sensitivity_formulas_used.get(name, \"Unknown\")\n",
        "                print(f\"\\n--- Model: {name} ---\"); print(f\"    Formula Type Used: {formula_used_key}\")\n",
        "                if isinstance(result_or_error_summary, str): print(f\"    -> Model Failed/Summary Error: {result_or_error_summary}\")\n",
        "                elif hasattr(result_or_error_summary, 'tables'):\n",
        "                     try:\n",
        "                         if hasattr(result_or_error_summary, 'tables') and isinstance(result_or_error_summary.tables, list):\n",
        "                              for table in result_or_error_summary.tables: print(table.as_text())\n",
        "                         else: print(str(result_or_error_summary))\n",
        "                     except Exception as e: print(f\"    -> Error formatting/printing summary tables for '{name}': {e}\");\n",
        "                     try: print(str(result_or_error_summary))\n",
        "                     except: print(\"    -> Could not even convert summary object to string.\")\n",
        "                else: print(f\"    -> Unknown result status stored for {name} (Type: {type(result_or_error_summary)}): {result_or_error_summary}\")\n",
        "\n",
        "print(f\"\\n\\n--- Preferred Model Selection & Comparison (Main Run) ---\")\n",
        "print(f\"  -> Preferred model selected: {preferred_model_key if preferred_model_key else 'None (Review Logs)'}\"); print(f\"  -> Review specification tests and theory.\")\n",
        "if preferred_model_key and RUN_WITHOUT_IMPUTATION_SENSITIVITY:\n",
        "    sens_key_map = {'Pooled_Interaction': 'Pooled_Interaction_Sens', 'FE_Entity_Simple': 'FE_Entity_Simple_Sens', 'FE_TwoWay_Simple': None, 'RE_Simple': None}\n",
        "    sens_key = sens_key_map.get(preferred_model_key)\n",
        "    if sens_key and sens_key in sensitivity_summaries:\n",
        "        sens_result_or_error = sensitivity_summaries[sens_key]\n",
        "        if not isinstance(sens_result_or_error, str): print(f\"  -> COMPARISON: Sensitivity '{sens_key}' ran successfully. Compare results.\")\n",
        "        else: print(f\"  -> COMPARISON NOTE: Sensitivity counterpart '{sens_key}' failed/skipped ({sens_result_or_error}).\")\n",
        "    elif sens_key: print(f\"  -> COMPARISON NOTE: Sensitivity counterpart '{sens_key}' not found in sensitivity results.\")\n",
        "    else: print(f\"  -> COMPARISON NOTE: No sensitivity counterpart defined for '{preferred_model_key}'.\")\n",
        "\n",
        "print(\"\\n--- Interpretation Summary (Refer to Step 7) ---\")\n",
        "if interpretation_provided: print(\"  -> Interpretation provided in Step 7.\")\n",
        "else: print(\"  -> No interpretation provided (model failures).\")\n",
        "\n",
        "print(\"\\n--- Specification Tests Summary (Main Run) ---\")\n",
        "if 'spec_test_df' in locals() and isinstance(spec_test_df, pd.DataFrame) and not spec_test_df.empty:\n",
        "    try: print(spec_test_df.to_string(index=False, justify='left', max_colwidth=60))\n",
        "    except Exception as print_err: print(f\"  -> Print error: {print_err}\"); print(spec_test_df)\n",
        "else: print(\"  -> Specification tests unavailable.\")\n",
        "\n",
        "print(\"\\n--- VIF Results (Main Run Data) ---\"); print(\"  (VIF > 10 indicates potential issues)\")\n",
        "if vif_results_total is not None and isinstance(vif_results_total, pd.DataFrame): print(\"\\n  VIF (Factors + Total ESG):\"); print(vif_results_total.sort_values('VIF', ascending=False).to_string(index=False))\n",
        "else: print(\"\\n  VIF check (Total ESG) N/A or failed.\")\n",
        "if vif_results_components is not None and isinstance(vif_results_components, pd.DataFrame): print(\"\\n  VIF (Factors + ESG Components):\"); print(vif_results_components.sort_values('VIF', ascending=False).to_string(index=False))\n",
        "else: print(\"\\n  VIF check (Components) N/A or failed.\")\n",
        "\n",
        "print(\"\\n\\n--- Overall Reliability Assessment & Disclaimers ---\")\n",
        "print(\"  - Data Quality: Verify sources (Steps 2 & 3 logs).\")\n",
        "print(f\"  - Imputation ({'MICE' if IMPUTE_DATA else 'Disabled'}): Main run {'used' if IMPUTE_DATA else 'did not use'} imputation.\")\n",
        "if IMPUTE_DATA and initial_missing_stats: high_missing_cols = [col for col, pct in initial_missing_stats.items() if pct > 25];\n",
        "if IMPUTE_DATA and initial_missing_stats and high_missing_cols: print(f\"    -> !!! CONCERN: High initial missingness (>25%): {high_missing_cols}.\")\n",
        "if IMPUTE_DATA: print(\"    -> Compare Main Run vs. Sensitivity Run (if successful).\")\n",
        "print(\"  - Model Specification & Validity:\")\n",
        "main_models_failed_count = sum(1 for res in model_summaries.values() if isinstance(res, str))\n",
        "if main_models_failed_count == len(model_summaries): print(\"    -> !!! CRITICAL: All main run models failed. Review Step 6 logs. !!!\")\n",
        "elif main_models_failed_count > 0: print(f\"    -> Warning: {main_models_failed_count} main run model(s) failed/summary error. Review logs.\")\n",
        "# Check specific model failures\n",
        "if 'Pooled_Interaction' in model_summaries and isinstance(model_summaries['Pooled_Interaction'], str): print(\"    -> Warning: Pooled OLS model failed or had summary error.\")\n",
        "elif 'Pooled_Interaction' in regression_results and isinstance(regression_results['Pooled_Interaction'], PanelEffectsResults):\n",
        "    try:\n",
        "        pooled_f_robust = regression_results['Pooled_Interaction'].f_statistic_robust.stat\n",
        "        if not np.isfinite(pooled_f_robust) or pooled_f_robust < 0 :\n",
        "             print(\"    -> Warning: Pooled OLS robust F-stat appears invalid. Check SE calculation.\")\n",
        "    except Exception:\n",
        "        print(\"    -> Warning: Could not access Pooled OLS robust F-statistic.\")\n",
        "        pass\n",
        "if 'RE_Simple' in model_summaries and isinstance(model_summaries['RE_Simple'], str): print(\"    -> Warning: RE model failed. Hausman test invalid.\")\n",
        "fe_models_to_check = ['FE_Entity_Simple', 'FE_TwoWay_Simple']\n",
        "for fe_key in fe_models_to_check:\n",
        "     if fe_key in model_summaries:\n",
        "          summary_val = model_summaries[fe_key]\n",
        "          if isinstance(summary_val, str) and ('Singular' in summary_val or 'Error' in summary_val): print(f\"    -> Warning: {fe_key} failed summary ({summary_val[:60]}...).\")\n",
        "          elif not isinstance(summary_val, str) and hasattr(summary_val, 'summary'):\n",
        "               summary_str = str(summary_val);\n",
        "               if 'Absorbed' in summary_str or 'dropped' in summary_str.lower(): print(f\"    -> Warning: {fe_key} summary indicates absorbed/dropped vars.\")\n",
        "\n",
        "print(\"    -> Note: FE/RE models used simplified spec (no category interactions). Pooled OLS used interactions.\")\n",
        "print(\"    -> Review model selection (Step 7) and theoretical fit.\")\n",
        "print(\"  - Data Characteristics: Check VIF results and Step 4 category warnings.\")\n",
        "print(\"\\n  --- Conclusion ---\"); print(\"  -> Treat findings with caution. Prioritize successful Sensitivity Run if Main had issues/imputation.\")\n",
        "\n",
        "print(\"\\n==============================================================================\")\n",
        "print(\"--- End of Consolidated Results ---\")\n",
        "print(\"==============================================================================\")\n",
        "\n",
        "print(f\"\\n--- Script Finished ({SCRIPT_VERSION}) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URoY4AceZOQV",
        "outputId": "b7d4e6e1-4715-4160-eca2-8850a46aeda2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting analysis for tickers: ['UPS', 'FDX', 'XPO', 'JYD', 'AMKBY', 'CNI', 'CP', 'UNP', 'CSX', 'ODFL', 'JBHT', 'ZIM']\n",
            "--- Global Transportation ESG Impact Analysis Script Started (Panel Only v14.1 - Transportation & FF DataReader) ---\n",
            "Analysis Period: 2015-01-01 to 2023-12-31\n",
            "ESG Lag: 1 months\n",
            "Imputation Enabled (Main Run - MICE): True\n",
            "Run Sensitivity without Imputation: True\n",
            "Factors Path: Data fetched from K. French Library\n",
            "ESG Data Path: /content/historic_esg_scores_global_transportation.csv (Source/Quality Not Verified by Script)\n",
            "\n",
            "--- 1. Downloading and Preparing Stock Returns ---\n",
            "  -> Stock price data processed for 12 tickers: ['AMKBY', 'CNI', 'CP', 'CSX', 'FDX', 'JBHT', 'JYD', 'ODFL', 'UNP', 'UPS', 'XPO', 'ZIM']\n",
            "  -> Stock monthly returns prepared: 2014-10-31 to 2024-12-31\n",
            "\n",
            "--- 2. Loading and Preparing Fama-French Factors ---\n",
            "  -> Downloading Fama-French factors using pandas-datareader...\n",
            "  -> Factors downloaded and merged successfully.\n",
            "  -> Raw factors shape: (132, 7)\n",
            "  -> No missing values detected in fetched factors.\n",
            "  -> Using 'rf' as RF.\n",
            "  -> Available factors identified: ['cma', 'hml', 'mkt_rf', 'rmw', 'smb']\n",
            "\n",
            "--- 3. Loading and Preparing ESG Data from CSV ---\n",
            "  -> Raw ESG data loaded. Shape: (915, 6)\n",
            "  -> Standardized ESG columns: ['date', 'total_score', 'e_score', 's_score', 'g_score', 'ticker']\n",
            "  -> Converting score columns to numeric: ['total_score', 'e_score', 's_score', 'g_score']\n",
            "  -> Common tickers identified: ['CNI', 'CP', 'CSX', 'FDX', 'JBHT', 'ODFL', 'UNP', 'UPS', 'XPO', 'ZIM'] (10 firms)\n",
            "    -> Tickers in Stock only: ['AMKBY', 'JYD']\n",
            "  -> Creating ESG panel from 2014-10-31 to 2023-12-31\n",
            "  -> Forward-filling ESG scores...\n",
            "  -> !!! WARNING: NaNs remain after ffill. Imputation will attempt. Counts:\n",
            "total_score    333\n",
            "e_score        333\n",
            "s_score        333\n",
            "g_score        333\n",
            "dtype: int64\n",
            "  -> ESG panel structure created. Shape: (1110, 6)\n",
            "\n",
            "--- 5. Checking for Multicollinearity (VIF) ---\n",
            "\n",
            "  Calculating VIF for: Factors + Total ESG\n",
            "        Variable    VIF\n",
            "             hml 4.8649\n",
            "             cma 4.0008\n",
            "             rmw 1.9476\n",
            "          mkt_rf 1.3215\n",
            "             smb 1.2618\n",
            "total_score_lag1 1.0157\n",
            "    -> VIF check passed (threshold=10).\n",
            "\n",
            "  Calculating VIF for: Factors + ESG Components\n",
            "    Variable     VIF\n",
            "s_score_lag1 21.0431\n",
            "g_score_lag1 15.7938\n",
            "e_score_lag1 14.3221\n",
            "         hml  4.8656\n",
            "         cma  4.0037\n",
            "         rmw  1.9501\n",
            "      mkt_rf  1.3216\n",
            "         smb  1.2650\n",
            "    -> !!! WARNING: High VIF (> 10): ['e_score_lag1', 's_score_lag1', 'g_score_lag1']. !!!\n",
            "\n",
            "  -> Primary ESG var for models: 'total_score_lag1'\n",
            "  -> Component ESG vars: ['e_score_lag1', 's_score_lag1', 'g_score_lag1']\n",
            "\n",
            "--- 6. Panel Regression Analysis (Main Run - Imputed Data if Enabled) ---\n",
            "\n",
            "  -> Formula for FE & RE models: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1\n",
            "  -> Attempting to set 'Medium' as reference category for Pooled OLS.\n",
            "     -> Found exact match: Using 'Medium'.\n",
            "  -> Formula for Pooled OLS (Interaction): ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1 * C(ESG_Category_lag1, Treatment(reference='Medium'))\n",
            "\n",
            "  --- Fitting Pooled_Interaction (Pooled) ---\n",
            "    Using Formula: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1 * C(ESG_Category_lag1, Treatment(reference='Medium'))\n",
            "     (Note: Using robust covariance for Pooled OLS)\n",
            "    -> Fit OK.\n",
            "    -> Summary generation OK.\n",
            "\n",
            "  --- Fitting RE_Simple (RE) ---\n",
            "    Using Formula: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1\n",
            "     (Note: Applying requested clustering to RE model)\n",
            "    -> Fit OK.\n",
            "    -> Summary generation OK.\n",
            "\n",
            "  --- Fitting FE_Entity_Simple (FE_Entity) ---\n",
            "    Using Formula: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1\n",
            "    -> Fit OK.\n",
            "    -> Summary generation OK.\n",
            "\n",
            "  --- Fitting FE_TwoWay_Simple (FE_TwoWay) ---\n",
            "    Using Formula: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1\n",
            "    -> Fit OK.\n",
            "    -> Summary generation OK.\n",
            "\n",
            "--- 6b. Panel Regression Analysis (Sensitivity Run - NO IMPUTATION) ---\n",
            "\n",
            "  --- Fitting Pooled_Interaction_Sens (Pooled) ---\n",
            "    Using Formula: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1 * C(ESG_Category_lag1, Treatment(reference='Medium'))\n",
            "     (Note: Using robust covariance for Pooled OLS)\n",
            "    -> Fit OK.\n",
            "    -> Summary generation OK.\n",
            "\n",
            "  --- Fitting FE_Entity_Simple_Sens (FE_Entity) ---\n",
            "    Using Formula: ExcessReturn ~ 1 + cma + hml + mkt_rf + rmw + smb + total_score_lag1\n",
            "    -> Fit OK.\n",
            "    -> Summary generation OK.\n",
            "\n",
            "--- 7. Specification Tests & Interpretation (using Main Run results) ---\n",
            "\n",
            "    Comparing FE (Simple) vs RE (Simple) - Hausman Test:\n",
            "      -> Performing Hausman test via model comparison...\n",
            "                     Model Comparison                     \n",
            "==========================================================\n",
            "                               FE_Simple         RE_Simple\n",
            "----------------------------------------------------------\n",
            "Dep. Variable               ExcessReturn      ExcessReturn\n",
            "Estimator                       PanelOLS     RandomEffects\n",
            "No. Observations                    1080              1080\n",
            "Cov. Est.                      Clustered         Clustered\n",
            "R-squared                         0.1880            0.1867\n",
            "R-Squared (Within)                0.1880            0.1880\n",
            "R-Squared (Between)              -0.7763           -0.7255\n",
            "R-Squared (Overall)               0.1866            0.1867\n",
            "F-statistic                       41.061            41.047\n",
            "P-value (F-stat)                  0.0000            0.0000\n",
            "=====================     ==============   ===============\n",
            "Intercept                        -0.1717           -0.1693\n",
            "                               (-30.621)         (-50.257)\n",
            "cma                               0.0091            0.0091\n",
            "                                (2.8368)          (2.8345)\n",
            "hml                               0.0005            0.0005\n",
            "                                (0.2235)          (0.2121)\n",
            "mkt_rf                            0.0129            0.0128\n",
            "                                (12.189)          (12.180)\n",
            "rmw                               0.0126            0.0125\n",
            "                                (9.1122)          (9.0944)\n",
            "smb                               0.0186            0.0187\n",
            "                                (17.536)          (17.565)\n",
            "total_score_lag1                  0.0016            0.0016\n",
            "                                (11.672)          (12.415)\n",
            "======================= ================ =================\n",
            "Effects                           Entity                  \n",
            "----------------------------------------------------------\n",
            "\n",
            "T-stats reported in parentheses\n",
            "\n",
            "    F-test for Poolability (Entity Effects):\n",
            "      F=0.3624, P-value=0.9527 (df_num=?, df_denom=1064)\n",
            "\n",
            "    F-test for Time Effects:\n",
            "      -> Time Effects F-stat (f_test_time) not available.\n",
            "\n",
            "--- Preferred Model Selection Logic (Main Run) ---\n",
            "  - Poolability Test Result: 'Cannot Reject Pooling (Pooled OK)'\n",
            "  - Hausman Test (Simple Models) Result: 'Check Table'\n",
            "  - Time Effects Test Result: 'Cannot Run'\n",
            "  - Logic: Pooling rejected & Entity FE valid.\n",
            "  - Logic: Hausman (Check Table), but Poolability rejects Pooled. Prioritizing FE Entity.\n",
            "  -> Tentative Preference: FE Entity (Simple).\n",
            "\n",
            "---> Final Preferred Model Selected (Main Run): FE_Entity_Simple <---\n",
            "\n",
            "--- Interpretation (Based on 'FE_Entity_Simple') ---\n",
            "    Interpreting Preferred Model: 'FE_Entity_Simple' (Formula Type: FE Entity Spec (Success))\n",
            "\n",
            "    Interpretation for 'total_score_lag1':\n",
            "      Model estimates avg effect controlling for Entity Fixed effects.\n",
            "      - Average Effect: Coeff=0.0016, SE=0.0001, Pval=0.0000 ***\n",
            "\n",
            "    Interpretation Notes:\n",
            "      - Results based on 'FE_Entity_Simple'. Check Pval.\n",
            "      - !!! CAVEAT: Uses imputed data. High initial missingness. Compare w/ Sensitivity. !!!\n",
            "      - Consider economic significance.\n",
            "\n",
            "\n",
            "==============================================================================\n",
            "--- 9. Consolidated Analysis Results (Panel Only v14.1 - Transportation & FF DataReader) ---\n",
            "==============================================================================\n",
            "\n",
            "--- Panel Model Summaries (Main Run - Imputed: True) ---\n",
            "\n",
            "--- Model: Pooled_Interaction ---\n",
            "    Formula Type Used: Pooled Spec (Robust SE) (Success)\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.1868\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -0.7074\n",
            "No. Observations:                1080   R-squared (Within):               0.1881\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.1868\n",
            "Time:                        17:59:24   Log-likelihood                    555.72\n",
            "Cov. Estimator:                Robust                                           \n",
            "                                        F-statistic:                      30.754\n",
            "Entities:                          10   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                  F(8,1071)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             28.764\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                  F(8,1071)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "================================================================================\n",
            "                                                              Parameter Estimates                                                              \n",
            "===============================================================================================================================================\n",
            "                                                                             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Intercept                                                                      -0.1705     0.0161    -10.587     0.0000     -0.2021     -0.1389\n",
            "cma                                                                             0.0091     0.0052     1.7467     0.0810     -0.0011      0.0193\n",
            "hml                                                                             0.0005     0.0038     0.1240     0.9013     -0.0070      0.0079\n",
            "mkt_rf                                                                          0.0128     0.0011     11.317     0.0000      0.0106      0.0151\n",
            "rmw                                                                             0.0125     0.0042     2.9606     0.0031      0.0042      0.0208\n",
            "smb                                                                             0.0187     0.0036     5.1142     0.0000      0.0115      0.0258\n",
            "total_score_lag1                                                                0.0016     0.0003     5.1849     0.0000      0.0010      0.0022\n",
            "C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low]                      0.0029     0.0310     0.0947     0.9245     -0.0578      0.0637\n",
            "total_score_lag1:C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low]    -0.0002     0.0006    -0.2721     0.7856     -0.0013      0.0010\n",
            "===============================================================================================================================================\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.1868\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -0.7074\n",
            "No. Observations:                1080   R-squared (Within):               0.1881\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.1868\n",
            "Time:                        17:59:24   Log-likelihood                    555.72\n",
            "Cov. Estimator:                Robust                                           \n",
            "                                        F-statistic:                      30.754\n",
            "Entities:                          10   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                  F(8,1071)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             28.764\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                  F(8,1071)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "                                                              Parameter Estimates                                                              \n",
            "===============================================================================================================================================\n",
            "                                                                             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Intercept                                                                      -0.1705     0.0161    -10.587     0.0000     -0.2021     -0.1389\n",
            "cma                                                                             0.0091     0.0052     1.7467     0.0810     -0.0011      0.0193\n",
            "hml                                                                             0.0005     0.0038     0.1240     0.9013     -0.0070      0.0079\n",
            "mkt_rf                                                                          0.0128     0.0011     11.317     0.0000      0.0106      0.0151\n",
            "rmw                                                                             0.0125     0.0042     2.9606     0.0031      0.0042      0.0208\n",
            "smb                                                                             0.0187     0.0036     5.1142     0.0000      0.0115      0.0258\n",
            "total_score_lag1                                                                0.0016     0.0003     5.1849     0.0000      0.0010      0.0022\n",
            "C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low]                      0.0029     0.0310     0.0947     0.9245     -0.0578      0.0637\n",
            "total_score_lag1:C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low]    -0.0002     0.0006    -0.2721     0.7856     -0.0013      0.0010\n",
            "===============================================================================================================================================\n",
            "\n",
            "\n",
            "\n",
            "--- Model: RE_Simple ---\n",
            "    Formula Type Used: RE Spec (Success)\n",
            "                        RandomEffects Estimation Summary                        \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.1867\n",
            "Estimator:              RandomEffects   R-squared (Between):             -0.7255\n",
            "No. Observations:                1080   R-squared (Within):               0.1880\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.1867\n",
            "Time:                        17:59:25   Log-likelihood                    555.63\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      41.047\n",
            "Entities:                          10   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                  F(6,1073)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             255.70\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                  F(6,1073)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "================================================================================\n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1693     0.0034    -50.257     0.0000     -0.1759     -0.1627\n",
            "cma                  0.0091     0.0032     2.8345     0.0047      0.0028      0.0154\n",
            "hml                  0.0005     0.0022     0.2121     0.8321     -0.0039      0.0049\n",
            "mkt_rf               0.0128     0.0011     12.180     0.0000      0.0108      0.0149\n",
            "rmw                  0.0125     0.0014     9.0944     0.0000      0.0098      0.0152\n",
            "smb                  0.0187     0.0011     17.565     0.0000      0.0166      0.0208\n",
            "total_score_lag1     0.0016     0.0001     12.415     0.0000      0.0013      0.0018\n",
            "====================================================================================\n",
            "                        RandomEffects Estimation Summary                        \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.1867\n",
            "Estimator:              RandomEffects   R-squared (Between):             -0.7255\n",
            "No. Observations:                1080   R-squared (Within):               0.1880\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.1867\n",
            "Time:                        17:59:25   Log-likelihood                    555.63\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      41.047\n",
            "Entities:                          10   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                  F(6,1073)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             255.70\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                  F(6,1073)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1693     0.0034    -50.257     0.0000     -0.1759     -0.1627\n",
            "cma                  0.0091     0.0032     2.8345     0.0047      0.0028      0.0154\n",
            "hml                  0.0005     0.0022     0.2121     0.8321     -0.0039      0.0049\n",
            "mkt_rf               0.0128     0.0011     12.180     0.0000      0.0108      0.0149\n",
            "rmw                  0.0125     0.0014     9.0944     0.0000      0.0098      0.0152\n",
            "smb                  0.0187     0.0011     17.565     0.0000      0.0166      0.0208\n",
            "total_score_lag1     0.0016     0.0001     12.415     0.0000      0.0013      0.0018\n",
            "====================================================================================\n",
            "\n",
            "--- Model: FE_Entity_Simple ---\n",
            "    Formula Type Used: FE Entity Spec (Success)\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.1880\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -0.7763\n",
            "No. Observations:                1080   R-squared (Within):               0.1880\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.1866\n",
            "Time:                        17:59:25   Log-likelihood                    557.29\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      41.061\n",
            "Entities:                          10   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                  F(6,1064)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             227.47\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                  F(6,1064)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "================================================================================\n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1717     0.0056    -30.621     0.0000     -0.1827     -0.1607\n",
            "cma                  0.0091     0.0032     2.8368     0.0046      0.0028      0.0154\n",
            "hml                  0.0005     0.0022     0.2235     0.8232     -0.0039      0.0049\n",
            "mkt_rf               0.0129     0.0011     12.189     0.0000      0.0108      0.0149\n",
            "rmw                  0.0126     0.0014     9.1122     0.0000      0.0099      0.0153\n",
            "smb                  0.0186     0.0011     17.536     0.0000      0.0165      0.0207\n",
            "total_score_lag1     0.0016     0.0001     11.672     0.0000      0.0014      0.0019\n",
            "====================================================================================\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.1880\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -0.7763\n",
            "No. Observations:                1080   R-squared (Within):               0.1880\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.1866\n",
            "Time:                        17:59:25   Log-likelihood                    557.29\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      41.061\n",
            "Entities:                          10   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                  F(6,1064)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             227.47\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                  F(6,1064)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1717     0.0056    -30.621     0.0000     -0.1827     -0.1607\n",
            "cma                  0.0091     0.0032     2.8368     0.0046      0.0028      0.0154\n",
            "hml                  0.0005     0.0022     0.2235     0.8232     -0.0039      0.0049\n",
            "mkt_rf               0.0129     0.0011     12.189     0.0000      0.0108      0.0149\n",
            "rmw                  0.0126     0.0014     9.1122     0.0000      0.0099      0.0153\n",
            "smb                  0.0186     0.0011     17.536     0.0000      0.0165      0.0207\n",
            "total_score_lag1     0.0016     0.0001     11.672     0.0000      0.0014      0.0019\n",
            "====================================================================================\n",
            "\n",
            "F-test for Poolability: 0.3624\n",
            "P-value: 0.9527\n",
            "Distribution: F(9,1064)\n",
            "\n",
            "Included effects: Entity\n",
            "\n",
            "--- Model: FE_TwoWay_Simple ---\n",
            "    Formula Type Used: FE TwoWay Spec (Success)\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.0038\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -0.0686\n",
            "No. Observations:                1080   R-squared (Within):               0.0130\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.0129\n",
            "Time:                        17:59:25   Log-likelihood                    1438.9\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      3.6760\n",
            "Entities:                          10   P-value                           0.0555\n",
            "Avg Obs:                       108.00   Distribution:                   F(1,962)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             4.0990\n",
            "                                        P-value                           0.0432\n",
            "Time periods:                     108   Distribution:                   F(1,962)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "================================================================================\n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1113     0.0093    -11.951     0.0000     -0.1295     -0.0930\n",
            "total_score_lag1     0.0004     0.0002     2.0246     0.0432   1.294e-05      0.0008\n",
            "====================================================================================\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.0038\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -0.0686\n",
            "No. Observations:                1080   R-squared (Within):               0.0130\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.0129\n",
            "Time:                        17:59:25   Log-likelihood                    1438.9\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      3.6760\n",
            "Entities:                          10   P-value                           0.0555\n",
            "Avg Obs:                       108.00   Distribution:                   F(1,962)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             4.0990\n",
            "                                        P-value                           0.0432\n",
            "Time periods:                     108   Distribution:                   F(1,962)\n",
            "Avg Obs:                      10.0000                                           \n",
            "Min Obs:                      10.0000                                           \n",
            "Max Obs:                      10.0000                                           \n",
            "                                                                                \n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1113     0.0093    -11.951     0.0000     -0.1295     -0.0930\n",
            "total_score_lag1     0.0004     0.0002     2.0246     0.0432   1.294e-05      0.0008\n",
            "====================================================================================\n",
            "\n",
            "F-test for Poolability: 42.580\n",
            "P-value: 0.0000\n",
            "Distribution: F(116,962)\n",
            "\n",
            "Included effects: Entity, Time\n",
            "\n",
            "\n",
            "--- Panel Model Summaries (Sensitivity Run - NO IMPUTATION) ---\n",
            "\n",
            "--- Model: Pooled_Interaction_Sens ---\n",
            "    Formula Type Used: Pooled Spec (Robust SE) (Success)\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.2009\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -10.014\n",
            "No. Observations:                 756   R-squared (Within):               0.2024\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.2009\n",
            "Time:                        17:59:25   Log-likelihood                    440.95\n",
            "Cov. Estimator:                Robust                                           \n",
            "                                        F-statistic:                      23.468\n",
            "Entities:                           7   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                   F(8,747)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             23.658\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                   F(8,747)\n",
            "Avg Obs:                       7.0000                                           \n",
            "Min Obs:                       7.0000                                           \n",
            "Max Obs:                       7.0000                                           \n",
            "                                                                                \n",
            "================================================================================\n",
            "                                                              Parameter Estimates                                                              \n",
            "===============================================================================================================================================\n",
            "                                                                             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Intercept                                                                      -0.1700     0.0175    -9.7323     0.0000     -0.2042     -0.1357\n",
            "cma                                                                             0.0153     0.0055     2.7699     0.0057      0.0045      0.0262\n",
            "hml                                                                            -0.0033     0.0040    -0.8307     0.4064     -0.0111      0.0045\n",
            "mkt_rf                                                                          0.0128     0.0013     10.009     0.0000      0.0103      0.0153\n",
            "rmw                                                                             0.0110     0.0046     2.3809     0.0175      0.0019      0.0201\n",
            "smb                                                                             0.0174     0.0041     4.2148     0.0000      0.0093      0.0255\n",
            "total_score_lag1                                                                0.0015     0.0003     4.7898     0.0000      0.0009      0.0021\n",
            "C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low]                      0.0018     0.0317     0.0583     0.9535     -0.0603      0.0640\n",
            "total_score_lag1:C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low] -2.706e-05     0.0006    -0.0471     0.9624     -0.0012      0.0011\n",
            "===============================================================================================================================================\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.2009\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -10.014\n",
            "No. Observations:                 756   R-squared (Within):               0.2024\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.2009\n",
            "Time:                        17:59:25   Log-likelihood                    440.95\n",
            "Cov. Estimator:                Robust                                           \n",
            "                                        F-statistic:                      23.468\n",
            "Entities:                           7   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                   F(8,747)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             23.658\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                   F(8,747)\n",
            "Avg Obs:                       7.0000                                           \n",
            "Min Obs:                       7.0000                                           \n",
            "Max Obs:                       7.0000                                           \n",
            "                                                                                \n",
            "                                                              Parameter Estimates                                                              \n",
            "===============================================================================================================================================\n",
            "                                                                             Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Intercept                                                                      -0.1700     0.0175    -9.7323     0.0000     -0.2042     -0.1357\n",
            "cma                                                                             0.0153     0.0055     2.7699     0.0057      0.0045      0.0262\n",
            "hml                                                                            -0.0033     0.0040    -0.8307     0.4064     -0.0111      0.0045\n",
            "mkt_rf                                                                          0.0128     0.0013     10.009     0.0000      0.0103      0.0153\n",
            "rmw                                                                             0.0110     0.0046     2.3809     0.0175      0.0019      0.0201\n",
            "smb                                                                             0.0174     0.0041     4.2148     0.0000      0.0093      0.0255\n",
            "total_score_lag1                                                                0.0015     0.0003     4.7898     0.0000      0.0009      0.0021\n",
            "C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low]                      0.0018     0.0317     0.0583     0.9535     -0.0603      0.0640\n",
            "total_score_lag1:C(ESG_Category_lag1, Treatment(reference='Medium'))[T.Low] -2.706e-05     0.0006    -0.0471     0.9624     -0.0012      0.0011\n",
            "===============================================================================================================================================\n",
            "\n",
            "\n",
            "\n",
            "--- Model: FE_Entity_Simple_Sens ---\n",
            "    Formula Type Used: FE Entity Spec (Success)\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.2024\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -10.660\n",
            "No. Observations:                 756   R-squared (Within):               0.2024\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.2008\n",
            "Time:                        17:59:25   Log-likelihood                    441.76\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      31.432\n",
            "Entities:                           7   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                   F(6,743)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             647.18\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                   F(6,743)\n",
            "Avg Obs:                       7.0000                                           \n",
            "Min Obs:                       7.0000                                           \n",
            "Max Obs:                       7.0000                                           \n",
            "                                                                                \n",
            "================================================================================\n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1717     0.0046    -37.020     0.0000     -0.1808     -0.1626\n",
            "cma                  0.0153     0.0015     9.9667     0.0000      0.0123      0.0184\n",
            "hml                 -0.0033     0.0014    -2.3022     0.0216     -0.0060     -0.0005\n",
            "mkt_rf               0.0128     0.0004     29.411     0.0000      0.0120      0.0137\n",
            "rmw                  0.0111     0.0016     6.8649     0.0000      0.0079      0.0142\n",
            "smb                  0.0174     0.0012     14.374     0.0000      0.0150      0.0197\n",
            "total_score_lag1     0.0016     0.0001     13.197     0.0000      0.0013      0.0018\n",
            "====================================================================================\n",
            "                          PanelOLS Estimation Summary                           \n",
            "================================================================================\n",
            "Dep. Variable:           ExcessReturn   R-squared:                        0.2024\n",
            "Estimator:                   PanelOLS   R-squared (Between):             -10.660\n",
            "No. Observations:                 756   R-squared (Within):               0.2024\n",
            "Date:                Mon, Apr 28 2025   R-squared (Overall):              0.2008\n",
            "Time:                        17:59:25   Log-likelihood                    441.76\n",
            "Cov. Estimator:             Clustered                                           \n",
            "                                        F-statistic:                      31.432\n",
            "Entities:                           7   P-value                           0.0000\n",
            "Avg Obs:                       108.00   Distribution:                   F(6,743)\n",
            "Min Obs:                       108.00                                           \n",
            "Max Obs:                       108.00   F-statistic (robust):             647.18\n",
            "                                        P-value                           0.0000\n",
            "Time periods:                     108   Distribution:                   F(6,743)\n",
            "Avg Obs:                       7.0000                                           \n",
            "Min Obs:                       7.0000                                           \n",
            "Max Obs:                       7.0000                                           \n",
            "                                                                                \n",
            "                                Parameter Estimates                                 \n",
            "====================================================================================\n",
            "                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept           -0.1717     0.0046    -37.020     0.0000     -0.1808     -0.1626\n",
            "cma                  0.0153     0.0015     9.9667     0.0000      0.0123      0.0184\n",
            "hml                 -0.0033     0.0014    -2.3022     0.0216     -0.0060     -0.0005\n",
            "mkt_rf               0.0128     0.0004     29.411     0.0000      0.0120      0.0137\n",
            "rmw                  0.0111     0.0016     6.8649     0.0000      0.0079      0.0142\n",
            "smb                  0.0174     0.0012     14.374     0.0000      0.0150      0.0197\n",
            "total_score_lag1     0.0016     0.0001     13.197     0.0000      0.0013      0.0018\n",
            "====================================================================================\n",
            "\n",
            "F-test for Poolability: 0.2666\n",
            "P-value: 0.9524\n",
            "Distribution: F(6,743)\n",
            "\n",
            "Included effects: Entity\n",
            "\n",
            "\n",
            "--- Preferred Model Selection & Comparison (Main Run) ---\n",
            "  -> Preferred model selected: FE_Entity_Simple\n",
            "  -> Review specification tests and theory.\n",
            "  -> COMPARISON: Sensitivity 'FE_Entity_Simple_Sens' ran successfully. Compare results.\n",
            "\n",
            "--- Interpretation Summary (Refer to Step 7) ---\n",
            "  -> Interpretation provided in Step 7.\n",
            "\n",
            "--- Specification Tests Summary (Main Run) ---\n",
            "Test                          Details                  P-value   Conclusion                       \n",
            "  Hausman (FE vs RE - Simple) Comparison table printed See Table                       Check Table\n",
            "F-test (Poolability - Entity)         F(?,1064)=0.3624    0.9527 Cannot Reject Pooling (Pooled OK)\n",
            "        F-test (Time Effects)  f_test_time unavailable         -                        Cannot Run\n",
            "\n",
            "--- VIF Results (Main Run Data) ---\n",
            "  (VIF > 10 indicates potential issues)\n",
            "\n",
            "  VIF (Factors + Total ESG):\n",
            "        Variable    VIF\n",
            "             hml 4.8649\n",
            "             cma 4.0008\n",
            "             rmw 1.9476\n",
            "          mkt_rf 1.3215\n",
            "             smb 1.2618\n",
            "total_score_lag1 1.0157\n",
            "\n",
            "  VIF (Factors + ESG Components):\n",
            "    Variable     VIF\n",
            "s_score_lag1 21.0431\n",
            "g_score_lag1 15.7938\n",
            "e_score_lag1 14.3221\n",
            "         hml  4.8656\n",
            "         cma  4.0037\n",
            "         rmw  1.9501\n",
            "      mkt_rf  1.3216\n",
            "         smb  1.2650\n",
            "\n",
            "\n",
            "--- Overall Reliability Assessment & Disclaimers ---\n",
            "  - Data Quality: Verify sources (Steps 2 & 3 logs).\n",
            "  - Imputation (MICE): Main run used imputation.\n",
            "    -> !!! CONCERN: High initial missingness (>25%): ['e_score_lag1', 'g_score_lag1', 's_score_lag1', 'total_score_lag1'].\n",
            "    -> Compare Main Run vs. Sensitivity Run (if successful).\n",
            "  - Model Specification & Validity:\n",
            "    -> Note: FE/RE models used simplified spec (no category interactions). Pooled OLS used interactions.\n",
            "    -> Review model selection (Step 7) and theoretical fit.\n",
            "  - Data Characteristics: Check VIF results and Step 4 category warnings.\n",
            "\n",
            "  --- Conclusion ---\n",
            "  -> Treat findings with caution. Prioritize successful Sensitivity Run if Main had issues/imputation.\n",
            "\n",
            "==============================================================================\n",
            "--- End of Consolidated Results ---\n",
            "==============================================================================\n",
            "\n",
            "--- Script Finished (Panel Only v14.1 - Transportation & FF DataReader) ---\n"
          ]
        }
      ]
    }
  ]
}