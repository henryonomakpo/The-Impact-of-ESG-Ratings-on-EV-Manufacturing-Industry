{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNifzKf4MS0EE6tN0FhvVDH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henryonomakpo/The-Impact-of-ESG-Ratings-on-EV-Manufacturing-Industry/blob/main/Data_Envelopment_Analysis_Airlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Envelopment Analysis for Airlines and\n",
        "Structural Equation Model for companies leveraging the Metaverse Technology."
      ],
      "metadata": {
        "id": "mQFw2yiml_pK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Envelopment Analysis for Airlines"
      ],
      "metadata": {
        "id": "d0hy4827VfZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pulp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzM-2FTnVnhy",
        "outputId": "4b8a181a-3694-43c8-c759-b6ee2f48d2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pulp\n",
            "  Downloading PuLP-2.9.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Downloading PuLP-2.9.0-py3-none-any.whl (17.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pulp import LpProblem, LpMinimize, LpVariable, lpSum, value\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "airlines_dea = pd.read_csv('/root')\n",
        "airlines_dea.head()\n",
        "# Set building\n",
        "K = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\"]\n",
        "I = [\"Aircraft\", \"Fuel\", \"Employee\"]\n",
        "J = [\"Passenger\", \"Freight\"]\n",
        "\n",
        "# Parameters building\n",
        "X = {\n",
        "    i: {\n",
        "        k: 0 for k in K\n",
        "    } for i in I\n",
        "}\n",
        "Y = {\n",
        "    j: {\n",
        "        k: 0 for k in K\n",
        "    } for j in J\n",
        "}\n",
        "\n",
        "# Import CSV data\n",
        "with open('airlines_data.csv', newline='') as csvfile:\n",
        "    rows = csv.DictReader(csvfile)\n",
        "    k = 0\n",
        "    for row in rows:\n",
        "        for i in I:\n",
        "            X[i][K[k]] = float(row[i])\n",
        "        for j in J:\n",
        "            Y[j][K[k]] = float(row[j])\n",
        "        k += 1\n",
        "\n",
        "# CRS_DEA_Model\n",
        "def getOverallEfficiency(r):\n",
        "\n",
        "    # Model Building\n",
        "    model = LpProblem('CRS_model', LpMinimize) # 建立一個新的model，命名為model\n",
        "\n",
        "    # Decision variables Building\n",
        "    theta_r = LpVariable(f'theta_r')\n",
        "    lambda_k = LpVariable.dicts(f'lambda_k', lowBound=0, indexs=K)\n",
        "\n",
        "    # Objective Function setting\n",
        "    model += theta_r\n",
        "\n",
        "    # Constraints setting\n",
        "    for i in I:\n",
        "        model += lpSum([\n",
        "                lambda_k[k] * X[i][k]\n",
        "            for k in K]) <= theta_r * float(X[i][K[r]])\n",
        "    for j in J:\n",
        "        model += lpSum([\n",
        "                lambda_k[k] * Y[j][k]\n",
        "            for k in K]) >= float(Y[j][K[r]])\n",
        "\n",
        "    # Model solving\n",
        "    model.solve()\n",
        "\n",
        "    return f'{K[r]}：{round(value(model.objective), 3)}\\n', value(model.objective)\n",
        "\n",
        "# VRS_DEA_Model\n",
        "def getTechnicalEfficiency(r):\n",
        "\n",
        "    # Model Building\n",
        "    model = LpProblem('VRS_model', LpMinimize) # model\n",
        "\n",
        "    # Decision variables Building\n",
        "    theta_r = LpVariable(f'theta_r')\n",
        "    lambda_k = LpVariable.dicts(f'lambda_k', lowBound=0, indexs = K)\n",
        "\n",
        "    # Objective Function setting\n",
        "    model += theta_r\n",
        "\n",
        "    # Constraints setting\n",
        "    for i in I:\n",
        "        model += lpSum([\n",
        "                lambda_k[k] * X[i][k]\n",
        "            for k in K]) <= theta_r * float(X[i][K[r]])\n",
        "    for j in J:\n",
        "        model += lpSum([\n",
        "                lambda_k[k] * Y[j][k]\n",
        "            for k in K]) >= float(Y[j][K[r]])\n",
        "    model += lpSum([ lambda_k[k] for k in K]) == 1\n",
        "\n",
        "    # model solving\n",
        "    model.solve()\n",
        "\n",
        "    return f'{K[r]}：{round(value(model.objective), 3)}\\n', value(model.objective)\n"
      ],
      "metadata": {
        "id": "Tm6qjUCBV17y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xJCHdoBDzDyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Steps:\n",
        "##### Stock Data Download: The yfinance package is used to download historical stock data for the specified companies from 2014-09-01 to 2023-09-01 at a monthly interval.\n",
        "##### Fama-French 5-Factor Data: The script downloads the Fama-French 5-factor data and merges it with the stock data.\n",
        "##### Missing Value Imputation: Missing values are handled using median imputation for numerical columns.\n",
        "##### Multicollinearity: Highly correlated variables are identified and removed based on a correlation threshold (0.9).\n",
        "##### Excess Return Calculation: The risk-free rate is subtracted from stock returns to calculate the excess return for each stock.\n",
        "##### Save Data: The final dataset is saved as a CSV file.\n",
        "##### CAPM, APT, and Fama-French Analysis: Linear regression is performed for each stock's excess return against the Fama-French factors.\n",
        "##### SEM & CFA: The script includes a model for CFA/SEM analysis and generates a path diagram."
      ],
      "metadata": {
        "id": "3XCa-Wk3mYOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9g2Rf8Fntzc",
        "outputId": "ae019bb7-4a67-447d-a2f4-7197051f35fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.43)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install factor_analyzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq2nWp_Mn0iU",
        "outputId": "506422ad-b7fd-4623-ae53-43b43bde4b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting factor_analyzer\n",
            "  Downloading factor_analyzer-0.5.1.tar.gz (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->factor_analyzer) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->factor_analyzer) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->factor_analyzer) (1.16.0)\n",
            "Building wheels for collected packages: factor_analyzer\n",
            "  Building wheel for factor_analyzer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for factor_analyzer: filename=factor_analyzer-0.5.1-py2.py3-none-any.whl size=42564 sha256=48aec8905df4f63d7dcaf70aed62099cc720ff6ee9371909d55bf34c1304b9c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/59/82/6493618e30ed1cb7a013b9e1b0c9e17de80b04dfcef4ba8a4d\n",
            "Successfully built factor_analyzer\n",
            "Installing collected packages: factor_analyzer\n",
            "Successfully installed factor_analyzer-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install semopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Rc-fFUoQ65",
        "outputId": "adf936e1-7a34-4948-c755-6f8586b38395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semopy\n",
            "  Downloading semopy-2.3.11.tar.gz (1.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from semopy) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from semopy) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from semopy) (2.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from semopy) (1.13.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from semopy) (1.5.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from semopy) (0.14.3)\n",
            "Collecting numdifftools (from semopy)\n",
            "  Downloading numdifftools-0.9.41-py2.py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->semopy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->semopy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->semopy) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->semopy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->semopy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->semopy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->semopy) (24.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->semopy) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->semopy) (1.16.0)\n",
            "Downloading numdifftools-0.9.41-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: semopy\n",
            "  Building wheel for semopy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for semopy: filename=semopy-2.3.11-py3-none-any.whl size=1659682 sha256=8240d31f90cf3664bc3ba7f40f49e79e5b86942350e51b8702e76d179c356758\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/ec/0d/0b294c02d8c4e9e80afea58839f2c1b4706770594bc99ec045\n",
            "Successfully built semopy\n",
            "Installing collected packages: numdifftools, semopy\n",
            "Successfully installed numdifftools-0.9.41 semopy-2.3.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import requests\n",
        "import io\n",
        "import statsmodels.api as sm\n",
        "from sklearn.decomposition import PCA\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "from semopy import Model, ModelMeans, semplot\n",
        "\n",
        "# Define the list of companies\n",
        "companies = [\"LOW\", \"ANSS\", \"PTC\", \"GE\", \"IBM\", \"SIE.DE\", \"BMW.DE\", \"ADS.DE\", \"ADSK\",\n",
        "             \"NKE\", \"NVDA\", \"BABA\", \"ADBE\", \"AAPL\", \"AVGO\", \"PYPL\", \"MSFT\", \"META\", \"AMZN\"]\n",
        "\n",
        "# Download monthly historical stock prices\n",
        "start_date = \"2014-09-01\"\n",
        "end_date = \"2023-09-01\"\n",
        "\n",
        "stock_data = yf.download(companies, start=start_date, end=end_date, interval=\"1mo\")\n",
        "stock_prices = stock_data['Adj Close']\n",
        "\n",
        "# Download Fama-French 5 Factor data\n",
        "#ff5_url = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_CSV.zip\"\n",
        "#response = requests.get(ff5_url)\n",
        "#ff5_data = pd.read_csv(io.BytesIO(response.content), skiprows=3, index_col=0)\n",
        "#ff5_data.index = pd.to_datetime(ff5_data.index, format='%Y%m')\n",
        "#ff5_data = ff5_data.loc[start_date:end_date]\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    ff_factors = pd.read_csv(\"F-F_Research_Data_5_Factors_2x3_CSV.zip\",\n",
        "                             skiprows=3,\n",
        "                             encoding='latin1',\n",
        "                             index_col=0)\n",
        "except Exception as e:\n",
        "    print(f\"Error reading file with latin1 encoding: {e}\")\n",
        "\n",
        "    try:\n",
        "        ff_factors = pd.read_csv(\"F-F_Research_Data_5_Factors_2x3_CSV.zip\",\n",
        "                                 skiprows=3,\n",
        "                                 encoding='iso-8859-1',\n",
        "                                 index_col=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file with iso-8859-1 encoding: {e}\")\n",
        "\n",
        "# Merge datasets\n",
        "merged_data = pd.merge(stock_prices, ff5_data, left_index=True, right_index=True, how='outer')\n",
        "\n",
        "# Address NAs by median imputation\n",
        "merged_data = merged_data.fillna(merged_data.median())\n",
        "\n",
        "# Calculate monthly returns\n",
        "returns = merged_data.pct_change()\n",
        "\n",
        "# Address multicollinearity using PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "pca.fit(returns.drop(['RF', 'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA'], axis=1))\n",
        "\n",
        "# Calculate excess returns\n",
        "risk_free_rate = returns['RF']\n",
        "excess_returns = returns.drop(['RF', 'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA'], axis=1).sub(risk_free_rate, axis=0)\n",
        "\n",
        "# Add '_ER' suffix to excess return columns\n",
        "excess_returns.columns = [col + '_ER' for col in excess_returns.columns]\n",
        "\n",
        "# Combine excess returns with Fama-French factors\n",
        "final_data = pd.concat([excess_returns, returns[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']]], axis=1)\n",
        "\n",
        "# Save as CSV\n",
        "final_data.to_csv(\"/Users/henryefeonomakpo/Downloads/1-Indra-H-Thesis idea/1-R prog code- stock /Quant-Finance-with-R-master/Tutorial Video Scripts/tidyverse/Metav_ER_ff5_esg.csv\")\n",
        "\n",
        "# Perform CAPM, APT, and Fama-French for each stock\n",
        "models = {}\n",
        "for stock in excess_returns.columns:\n",
        "    # CAPM\n",
        "    X = sm.add_constant(final_data['Mkt-RF'])\n",
        "    y = final_data[stock]\n",
        "    models[stock] = {'CAPM': sm.OLS(y, X).fit()}\n",
        "\n",
        "    # APT (using Fama-French factors as proxies for economic factors)\n",
        "    X = sm.add_constant(final_data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']])\n",
        "    models[stock]['APT'] = sm.OLS(y, X).fit()\n",
        "\n",
        "    # Fama-French 5-Factor\n",
        "    models[stock]['FF5'] = sm.OLS(y, X).fit()\n",
        "\n",
        "# Perform CFA\n",
        "fa = FactorAnalyzer(n_factors=5, rotation=None)\n",
        "fa.fit(final_data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']])\n",
        "\n",
        "# Perform SEM\n",
        "sem_model = \"\"\"\n",
        "# Measurement model\n",
        "Market =~ Mkt-RF\n",
        "Size =~ SMB\n",
        "Value =~ HML\n",
        "Profitability =~ RMW\n",
        "Investment =~ CMA\n",
        "\n",
        "# Structural model\n",
        "AAPL_ER ~ Market + Size + Value + Profitability + Investment\n",
        "\"\"\"\n",
        "\n",
        "sem = Model(sem_model)\n",
        "sem.fit(final_data)\n",
        "\n",
        "# Draw path diagram\n",
        "semplot(sem, \"sem_path_diagram.png\")\n",
        "\n",
        "print(\"Analysis complete. Results saved in Metav_ER_ff5_esg.csv and sem_path_diagram.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "x4kSbXltnhTT",
        "outputId": "134d48c3-7b13-41f3-f968-0903ceeb85ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  19 of 19 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading file with latin1 encoding: [Errno 2] No such file or directory: 'F-F_Research_Data_5_Factors_2x3_CSV.zip'\n",
            "Error reading file with iso-8859-1 encoding: [Errno 2] No such file or directory: 'F-F_Research_Data_5_Factors_2x3_CSV.zip'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot convert [[nan nan nan ... '2021   ' '2022  ' '2023   ']\n [nan nan nan ... '16.77   ' '-18.61   ' '13.37   ']\n [nan nan nan ... '-1.18    ' '-7.48   ' '-8.19    ']\n ...\n [nan nan nan ... '9.41   ' '-3.41   ' '0.29    ']\n [nan nan nan ... '-5.10    ' '11.80    ' '5.71    ']\n [nan nan nan ... '0.04' '1.42' '4.95']] to numeric",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-655e9e27a61c>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Address NAs by median imputation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmerged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Calculate monthly returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11704\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11705\u001b[0m     ):\n\u001b[0;32m> 11706\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11707\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11708\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"median\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12429\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12430\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 12431\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  12432\u001b[0m             \u001b[0;34m\"median\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12433\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12377\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  12378\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12379\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11560\u001b[0m         \u001b[0;31m# After possibly _get_data and transposing, we are now in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11561\u001b[0m         \u001b[0;31m#  simple case where we can use BlockManager.reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11562\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11563\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"boolean\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mres_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0mnbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m             \u001b[0mres_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mblk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11479\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11480\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11481\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11483\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mixed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot convert {values} to numeric\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert [[nan nan nan ... '2021   ' '2022  ' '2023   ']\n [nan nan nan ... '16.77   ' '-18.61   ' '13.37   ']\n [nan nan nan ... '-1.18    ' '-7.48   ' '-8.19    ']\n ...\n [nan nan nan ... '9.41   ' '-3.41   ' '0.29    ']\n [nan nan nan ... '-5.10    ' '11.80    ' '5.71    ']\n [nan nan nan ... '0.04' '1.42' '4.95']] to numeric"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8BXAAYxoVbAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 2"
      ],
      "metadata": {
        "id": "KY6q2pOaoxzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "kqSWoTD2zHtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define stock tickers\n",
        "companies = [\"LOW\", \"ANSS\", \"PTC\", \"GE\", \"IBM\", \"SIE.DE\", \"BMW.DE\", \"ADS.DE\",\n",
        "             \"ADSK\", \"NKE\", \"NVDA\", \"BABA\", \"ADBE\", \"AAPL\", \"AVGO\", \"PYPL\",\n",
        "             \"MSFT\", \"META\", \"AMZN\"]\n",
        "\n",
        "start_date = \"2014-09-01\"\n",
        "end_date = \"2023-09-01\"\n",
        "\n",
        "# Download stock data with retry logic for failed downloads\n",
        "def download_data(tickers, start, end):\n",
        "    stock_data = yf.download(tickers, start=start, end=end, interval='1mo')\n",
        "    for ticker in tickers:\n",
        "        if ticker not in stock_data.columns.levels[1]:\n",
        "            print(f\"Retrying for {ticker}...\")\n",
        "            data_retry = yf.download(ticker, start=start, end=end, interval='1mo')\n",
        "            stock_data[ticker] = data_retry['Adj Close']\n",
        "    return stock_data['Adj Close']\n",
        "\n",
        "# Retry downloading failed stock data\n",
        "stock_data = download_data(companies, start_date, end_date)\n",
        "\n",
        "# Download Fama-French 5-factor data\n",
        "ff5_url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/Europe_5_Factors_CSV.zip'\n",
        "ff5_data = pd.read_csv(ff5_url, skiprows=3)\n",
        "\n",
        "# Cleaning Fama-French 5-factor data\n",
        "ff5_data = ff5_data.dropna(subset=['Date'])  # Drop rows where 'Date' is missing or improperly formatted\n",
        "ff5_data['Date'] = ff5_data['Date'].str.strip()  # Remove extra spaces\n",
        "ff5_data['Date'] = pd.to_datetime(ff5_data['Date'], format='%Y%m', errors='coerce')  # Convert to datetime\n",
        "ff5_data.dropna(subset=['Date'], inplace=True)  # Drop rows where conversion failed\n",
        "\n",
        "# Clean and format Fama-French data\n",
        "ff5_data.columns = ['Date', 'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF']\n",
        "ff5_data['Date'] = pd.to_datetime(ff5_data['Date'], format='%Y-%m')\n",
        "\n",
        "# Merge stock data and Fama-French data\n",
        "data = pd.merge(stock_data, ff5_data, left_index=True, right_on='Date')\n",
        "\n",
        "# Handle missing values (imputation with median for numeric columns)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data.iloc[:, 1:] = imputer.fit_transform(data.iloc[:, 1:])\n",
        "\n",
        "# Check and address multicollinearity\n",
        "corr_matrix = data.corr()\n",
        "high_corr = corr_matrix.index[corr_matrix.abs().any() > 0.9]\n",
        "data.drop(columns=high_corr, inplace=True)\n",
        "\n",
        "# Calculate Excess Return for each stock and add \"_ER\" column\n",
        "rf = data['RF']\n",
        "for stock in companies:\n",
        "    data[stock + '_ER'] = data[stock] - rf\n",
        "\n",
        "# Save dataset to CSV\n",
        "output_file = '/Users/henryefeonomakpo/Downloads/1-Indra-H-Thesis idea/1-R prog code- stock /Quant-Finance-with-R-master/Tutorial Video Scripts/tidyverse/Metav_ER_ff5_esg.csv'\n",
        "data.to_csv(output_file, index=False)\n",
        "\n",
        "# Function to perform CAPM, Fama-French, APT\n",
        "def perform_regression(stock_er, factors):\n",
        "    X = sm.add_constant(factors)\n",
        "    model = sm.OLS(stock_er, X).fit()\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "# CAPM, APT, and Fama-French models\n",
        "factors = data[['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']]\n",
        "for stock in companies:\n",
        "    stock_er = data[stock + '_ER']\n",
        "    print(f\"Results for {stock}:\")\n",
        "    perform_regression(stock_er, factors)\n",
        "\n",
        "# Structural Equation Modeling (SEM) - using 'lavaan' equivalent in Python\n",
        "from semopy import Model\n",
        "\n",
        "# CFA & SEM model structure\n",
        "sem_model = \"\"\"\n",
        "    ESG =~ Env_Risk + Soc_Risk + Gov_Risk\n",
        "    ER ~ ESG\n",
        "\"\"\"\n",
        "\n",
        "# Prepare data for SEM (Assume ESG columns exist)\n",
        "esg_columns = ['Env_Risk', 'Soc_Risk', 'Gov_Risk']\n",
        "sem_data = data[esg_columns + ['ER']].dropna()\n",
        "\n",
        "# Build and fit SEM model\n",
        "model = Model(sem_model)\n",
        "model.fit(sem_data)\n",
        "\n",
        "# Path Diagram\n",
        "from semopy import path_diagram\n",
        "path_diagram(model, 'sem_path_diagram.png')\n",
        "\n",
        "# Show the fitted SEM model summary\n",
        "print(model.inspect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "mFozo39tmYnG",
        "outputId": "c9a3bdf5-4d87-4674-be10-50c40a15e3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  19 of 19 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "['Date']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-155a3aa56cd5>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Cleaning Fama-French 5-factor data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mff5_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff5_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Drop rows where 'Date' is missing or improperly formatted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mff5_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff5_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove extra spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mff5_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff5_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y%m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ['Date']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Structural Equation Modeling (SEM) - using 'lavaan' equivalent in Python\n",
        "from semopy import Model\n",
        "\n",
        "# CFA & SEM model structure\n",
        "sem_model = \"\"\"\n",
        "    ESG =~ Env_Risk + Soc_Risk + Gov_Risk\n",
        "    ER ~ ESG\n",
        "\"\"\"\n",
        "\n",
        "# Prepare data for SEM (Assume ESG columns exist)\n",
        "esg_columns = ['Env_Risk', 'Soc_Risk', 'Gov_Risk']\n",
        "sem_data = data[esg_columns + ['ER']].dropna()\n",
        "\n",
        "# Build and fit SEM model\n",
        "model = Model(sem_model)\n",
        "model.fit(sem_data)\n",
        "\n",
        "# Path Diagram\n",
        "from semopy import path_diagram\n",
        "path_diagram(model, 'sem_path_diagram.png')\n",
        "\n",
        "# Show the fitted SEM model summary\n",
        "print(model.inspect())\n"
      ],
      "metadata": {
        "id": "zIGGU1UynNEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}